{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbQlXc87hi5U",
        "outputId": "6f634378-e309-44da-e531-af8389a1510f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.26.4)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.1)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n"
          ]
        }
      ],
      "source": [
        "# ConexÃ£o do Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# InstalaÃ§Ã£o de biblioteca\n",
        "!pip install rasterio\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import rasterio\n",
        "from rasterio.enums import Resampling\n",
        "import numpy as np\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from rasterio.windows import Window\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import tensorflow\n",
        "import keras\n",
        "from rasterio.shutil import copy\n",
        "from rasterio.warp import transform\n",
        "\n",
        "#DeclaraÃ§Ã£o de variaveis\n",
        "bs = \"/content/drive/MyDrive/Unb/Plantio_direto/Patches_32x32\"\n",
        "\n",
        "#Define funÃ§Ãµes\n",
        "def detalhes(tiff_path):\n",
        "    \"\"\"Exibe informaÃ§Ãµes detalhadas sobre um arquivo TIFF geoespacial.\"\"\"\n",
        "    with rasterio.open(tiff_path) as dataset:\n",
        "        print(f\"ğŸ“‚ Arquivo: {tiff_path}\")\n",
        "        print(f\"â¡ï¸ CRS: {dataset.crs}\")  # Sistema de Coordenadas de ReferÃªncia\n",
        "        print(f\"â¡ï¸ ResoluÃ§Ã£o: {dataset.res[0]}, {dataset.res[1]}\")  # Tamanho do pixel\n",
        "        print(f\"â¡ï¸ DimensÃµes: {dataset.width} x {dataset.height} (Largura x Altura)\")\n",
        "        print(f\"â¡ï¸ Quantidade de bandas: {dataset.count}\")\n",
        "        print(f\"â¡ï¸ ExtensÃ£o: {dataset.bounds}\")  # Bounding box\n",
        "        print(f\"â¡ï¸ Tipo de dado das bandas: {[dataset.dtypes[i] for i in range(dataset.count)]}\")\n",
        "        print(f\"â¡ï¸ Perfil do dataset: {dataset.profile}\")  # Metadados gerais\n",
        "        print(f\"â¡ï¸ TransformaÃ§Ã£o Afim (GeoTransform): {dataset.transform}\")  # Matriz de transformaÃ§Ã£o espacial\n",
        "        print(f\"â¡ï¸ Valor NoData: {dataset.nodata}\")  # Valor que representa ausÃªncia de dados\n",
        "        print(f\"â¡ï¸ Metadata: {dataset.meta}\")  # Metadados completos\n",
        "\n",
        "#visualiza amostra do mapa\n",
        "def visualizar_tiff_reduzido(file_path, fator_reducao=10, cmap='gray', canal=1):\n",
        "    with rasterio.open(file_path) as src:\n",
        "        # Reduz a resoluÃ§Ã£o da primeira banda\n",
        "        small_window = src.read(canal, out_shape=(src.height // fator_reducao, src.width // fator_reducao))\n",
        "        # Exibe a imagem reduzida\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.imshow(small_window, cmap=cmap)\n",
        "        # plt.colorbar()\n",
        "        plt.title(f\"VisualizaÃ§Ã£o rÃ¡pida do TIFF (reduzido {fator_reducao}x)\")\n",
        "        plt.show()\n",
        "\n",
        "def rgb(tiff_path, bandas_rgb=(4, 3, 2), gamma=1.2, percentil=(1, 99)):\n",
        "    \"\"\"\n",
        "    Exibe a composiÃ§Ã£o RGB de um patch TIFF e imprime suas coordenadas geogrÃ¡ficas.\n",
        "\n",
        "    Args:\n",
        "        tiff_path (str): Caminho do arquivo TIFF.\n",
        "        bandas_rgb (tuple): Ãndices das bandas para o RGB (padrÃ£o: (4, 3, 2)).\n",
        "        gamma (float): Fator de correÃ§Ã£o gama para melhorar contraste.\n",
        "        percentil (tuple): Percentis para normalizaÃ§Ã£o (padrÃ£o: 1% e 99%).\n",
        "    \"\"\"\n",
        "    with rasterio.open(tiff_path) as dataset:\n",
        "        if max(bandas_rgb) > dataset.count:\n",
        "            print(f\"Erro: O arquivo tem apenas {dataset.count} bandas.\")\n",
        "            return\n",
        "\n",
        "        # Ler as bandas RGB\n",
        "        r = dataset.read(bandas_rgb[0]).astype(np.float32)\n",
        "        g = dataset.read(bandas_rgb[1]).astype(np.float32)\n",
        "        b = dataset.read(bandas_rgb[2]).astype(np.float32)\n",
        "\n",
        "        # Normalizar usando percentis mais conservadores\n",
        "        def normalizar(banda):\n",
        "            min_val, max_val = np.nanpercentile(banda, percentil)\n",
        "            return np.clip((banda - min_val) / (max_val - min_val + 1e-6), 0, 1)\n",
        "\n",
        "        r, g, b = map(normalizar, [r, g, b])\n",
        "\n",
        "        # Aplicar correÃ§Ã£o gama\n",
        "        def corrigir_gamma(banda, gamma):\n",
        "            return np.power(banda, 1/gamma)\n",
        "\n",
        "        r, g, b = map(lambda x: corrigir_gamma(x, gamma), [r, g, b])\n",
        "\n",
        "        # Criar imagem RGB\n",
        "        rgb = np.dstack((r, g, b))\n",
        "\n",
        "        # Obter coordenadas geogrÃ¡ficas do centro e cantos do patch\n",
        "        transform = dataset.transform\n",
        "        height, width = dataset.height, dataset.width\n",
        "\n",
        "        # Canto superior esquerdo\n",
        "        lon1, lat1 = rasterio.transform.xy(transform, 0, 0)\n",
        "        # Canto inferior direito\n",
        "        lon2, lat2 = rasterio.transform.xy(transform, height - 1, width - 1)\n",
        "        # Centro do patch\n",
        "        center_x, center_y = width // 2, height // 2\n",
        "        lon_c, lat_c = rasterio.transform.xy(transform, center_y, center_x)\n",
        "\n",
        "        # Verificar se a projeÃ§Ã£o Ã© geogrÃ¡fica (lat/lon)\n",
        "        if dataset.crs and dataset.crs.to_epsg() not in [4326]:  # Se nÃ£o for WGS 84\n",
        "            from rasterio.warp import transform\n",
        "            lon1, lat1 = transform(dataset.crs, 'EPSG:4326', [lon1], [lat1])\n",
        "            lon2, lat2 = transform(dataset.crs, 'EPSG:4326', [lon2], [lat2])\n",
        "            lon_c, lat_c = transform(dataset.crs, 'EPSG:4326', [lon_c], [lat_c])\n",
        "            lon1, lat1, lon2, lat2, lon_c, lat_c = lon1[0], lat1[0], lon2[0], lat2[0], lon_c[0], lat_c[0]\n",
        "\n",
        "        # Exibir coordenadas geogrÃ¡ficas\n",
        "        print(f\"ğŸ“ Coordenadas do patch:\")\n",
        "        print(f\"   Superior Esquerdo:  ({lat1:.6f}, {lon1:.6f})\")\n",
        "        print(f\"   Inferior Direito:   ({lat2:.6f}, {lon2:.6f})\")\n",
        "        print(f\"   Centro:             ({lat_c:.6f}, {lon_c:.6f})\")\n",
        "\n",
        "        # Exibir a imagem RGB\n",
        "        plt.figure(figsize=(5, 5))\n",
        "        plt.imshow(rgb)\n",
        "        plt.title(f\"ComposiÃ§Ã£o RGB - ({lat_c:.6f}, {lon_c:.6f})\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def analisar_patch(tiff_path, banda=18):\n",
        "    \"\"\"\n",
        "    Analisa um patch TIFF e exibe estatÃ­sticas da banda selecionada.\n",
        "\n",
        "    Args:\n",
        "        tiff_path (str): Caminho do arquivo TIFF.\n",
        "        banda (int): Ãndice da banda a ser analisada (padrÃ£o: 18).\n",
        "    \"\"\"\n",
        "    if not os.path.exists(tiff_path):\n",
        "        print(f\"Arquivo nÃ£o encontrado: {tiff_path}\")\n",
        "        return\n",
        "\n",
        "    with rasterio.open(tiff_path) as dataset:\n",
        "        if banda > dataset.count:\n",
        "            print(f\"O arquivo tem apenas {dataset.count} bandas. A banda {banda} nÃ£o existe.\")\n",
        "            return\n",
        "\n",
        "        banda_18 = dataset.read(banda).astype(np.float32)  # Ler banda 18 como float\n",
        "\n",
        "        # Exibir estatÃ­sticas\n",
        "        print(f\"ğŸ“‚ Analisando: {tiff_path}\")\n",
        "        print(f\"ğŸ“ DimensÃµes: {banda_18.shape}\")\n",
        "        print(f\"âš« Valor NoData do TIFF: {dataset.nodata}\")\n",
        "        print(f\"ğŸ”¢ Valores Ãºnicos: {np.unique(banda_18)}\")\n",
        "        print(f\"ğŸ” MÃ­nimo: {np.min(banda_18)}, MÃ¡ximo: {np.max(banda_18)}\")\n",
        "        print(f\"ğŸ“Š MÃ©dia: {np.mean(banda_18)}, Desvio padrÃ£o: {np.std(banda_18)}\")\n",
        "        print(f\"ğŸ›‘ Pixels exatamente 0.0: {np.sum(banda_18 == 0.0)} / {banda_18.size}\")\n",
        "        print(f\"ğŸš€ Pixels exatamente 1.0: {np.sum(banda_18 == 1.0)} / {banda_18.size}\")\n",
        "        print(f\"â“ Pixels NaN: {np.sum(np.isnan(banda_18))}\")\n",
        "\n",
        "        # Visualizar a banda 18\n",
        "        import matplotlib.pyplot as plt\n",
        "        plt.imshow(banda_18, cmap=\"gray\")\n",
        "        plt.colorbar()\n",
        "        plt.title(\"Banda 18 - Patch analisado\")\n",
        "        plt.show()\n",
        "\n",
        "def visualizar_patch_aleatorio(pasta_patches):\n",
        "    \"\"\"\n",
        "    Seleciona aleatoriamente um arquivo TIFF da pasta e exibe suas bandas.\n",
        "\n",
        "    Args:\n",
        "        pasta_patches (str): Caminho da pasta contendo os patches TIFF.\n",
        "    \"\"\"\n",
        "    # Obter a lista de arquivos na pasta\n",
        "    arquivos_tiff = [f for f in os.listdir(pasta_patches) if f.endswith(\".tiff\") or f.endswith(\".tif\")]\n",
        "\n",
        "    # Verificar se hÃ¡ arquivos na pasta\n",
        "    if not arquivos_tiff:\n",
        "        print(\"Nenhum arquivo TIFF encontrado na pasta.\")\n",
        "        return\n",
        "\n",
        "    # Escolher um arquivo aleatoriamente\n",
        "    tiff_escolhido = random.choice(arquivos_tiff)\n",
        "    tiff_path = os.path.join(pasta_patches, tiff_escolhido)\n",
        "\n",
        "    print(f\"ğŸ“‚ Exibindo: {tiff_escolhido}\")\n",
        "\n",
        "    # Abrir o arquivo e exibir as descriÃ§Ãµes das bandas\n",
        "    with rasterio.open(tiff_path) as dataset:\n",
        "        num_bands = dataset.count\n",
        "        fig, axes = plt.subplots(nrows=(num_bands // 5) + 1, ncols=5, figsize=(15, (num_bands // 5) * 3))\n",
        "\n",
        "        for i in range(num_bands):\n",
        "            band = dataset.read(i + 1).astype(np.float32)  # Lendo a banda (comeÃ§a do 1)\n",
        "\n",
        "            # Obter valores mÃ­nimo e mÃ¡ximo da banda\n",
        "            band_min, band_max = np.nanmin(band), np.nanmax(band)\n",
        "            print(f\"ğŸ“Š Banda {i+1} - MÃ­n: {band_min}, MÃ¡x: {band_max}\")\n",
        "\n",
        "            # Evitar normalizaÃ§Ã£o errada se a banda for constante\n",
        "            if band_max == band_min:\n",
        "                # band = np.zeros_like(band)  # Evita dividir por zero, mantendo preto\n",
        "                band = np.ones_like(band)  # Evita dividir por zero, mantendo branco\n",
        "            else:\n",
        "                band = (band - band_min) / (band_max - band_min + 1e-6)  # NormalizaÃ§Ã£o\n",
        "\n",
        "            # Selecionando eixo correto na grade\n",
        "            ax = axes[i // 5, i % 5] if num_bands > 5 else axes[i]\n",
        "            ax.imshow(band, cmap='gray')\n",
        "            ax.set_title(f\"Banda {i+1}\")\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "        # Removendo eixos vazios, se houver\n",
        "        for j in range(i+1, len(axes.flatten())):\n",
        "            fig.delaxes(axes.flatten()[j])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def visualizar_patch_aleatorio(pasta_patches):\n",
        "    \"\"\"\n",
        "    Seleciona aleatoriamente um arquivo TIFF da pasta e exibe suas bandas.\n",
        "\n",
        "    Args:\n",
        "        pasta_patches (str): Caminho da pasta contendo os patches TIFF.\n",
        "    \"\"\"\n",
        "    # Obter a lista de arquivos na pasta\n",
        "    arquivos_tiff = [f for f in os.listdir(pasta_patches) if f.endswith(\".tiff\") or f.endswith(\".tif\")]\n",
        "\n",
        "    # Verificar se hÃ¡ arquivos na pasta\n",
        "    if not arquivos_tiff:\n",
        "        print(\"Nenhum arquivo TIFF encontrado na pasta.\")\n",
        "        return\n",
        "\n",
        "    # Escolher um arquivo aleatoriamente\n",
        "    tiff_escolhido = random.choice(arquivos_tiff)\n",
        "    tiff_path = os.path.join(pasta_patches, tiff_escolhido)\n",
        "\n",
        "    print(f\"ğŸ“‚ Exibindo: {tiff_escolhido}\")\n",
        "\n",
        "    # Abrir o arquivo e exibir as descriÃ§Ãµes das bandas\n",
        "    with rasterio.open(tiff_path) as dataset:\n",
        "        num_bands = dataset.count\n",
        "        fig, axes = plt.subplots(nrows=(num_bands // 5) + 1, ncols=5, figsize=(15, (num_bands // 5) * 3))\n",
        "\n",
        "        for i in range(num_bands):\n",
        "            band = dataset.read(i + 1).astype(np.float32)  # Lendo a banda (comeÃ§a do 1)\n",
        "\n",
        "            # Obter valores mÃ­nimo e mÃ¡ximo da banda\n",
        "            band_min, band_max = np.nanmin(band), np.nanmax(band)\n",
        "            print(f\"ğŸ“Š Banda {i+1} - MÃ­n: {band_min}, MÃ¡x: {band_max}\")\n",
        "\n",
        "            # Evitar normalizaÃ§Ã£o errada se a banda for constante\n",
        "            if band_max == band_min:\n",
        "                # band = np.zeros_like(band)  # Evita dividir por zero, mantendo preto\n",
        "                band = np.ones_like(band)  # Evita dividir por zero, mantendo branco\n",
        "            else:\n",
        "                band = (band - band_min) / (band_max - band_min + 1e-6)  # NormalizaÃ§Ã£o\n",
        "\n",
        "            # Selecionando eixo correto na grade\n",
        "            ax = axes[i // 5, i % 5] if num_bands > 5 else axes[i]\n",
        "            ax.imshow(band, cmap='gray', vmin=0, vmax=1)\n",
        "            ax.set_title(f\"Banda {i+1}\")\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "        # Removendo eixos vazios, se houver\n",
        "        for j in range(i+1, len(axes.flatten())):\n",
        "            fig.delaxes(axes.flatten()[j])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "IBP7VXiNCavb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from rasterio.enums import Resampling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "\n",
        "# ğŸ“Œ Configurar caminhos no Google Drive\n",
        "pasta_patches = \"/content/drive/MyDrive/Unb/Plantio_direto/Patches_32x32\"\n",
        "pasta_checkpoint = \"/content/drive/MyDrive/Unb/Autoencoder_Checkpoints\"\n",
        "pasta_logs = \"/content/drive/MyDrive/Unb/Autoencoder_Logs\"\n",
        "\n",
        "# Criar diretÃ³rios, se nÃ£o existirem\n",
        "os.makedirs(pasta_checkpoint, exist_ok=True)\n",
        "os.makedirs(pasta_logs, exist_ok=True)\n",
        "\n",
        "# ğŸ”¹ Definir os hiperparÃ¢metros\n",
        "IMG_SIZE = 32\n",
        "NUM_BANDS = 16  # 16 bandas espectrais\n",
        "LATENT_DIM = 128  # DimensÃ£o do espaÃ§o latente\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "\n",
        "# ğŸ”¹ Listar arquivos TIFF na pasta\n",
        "arquivos_tiff = [os.path.join(pasta_patches, f) for f in os.listdir(pasta_patches) if f.endswith(\".tif\")]\n",
        "\n",
        "# ğŸ”¹ FunÃ§Ã£o para carregar imagens TIFF como arrays normalizados\n",
        "def carregar_patches(arquivos_tiff):\n",
        "    imagens = []\n",
        "    for arquivo in arquivos_tiff:\n",
        "        with rasterio.open(arquivo) as dataset:\n",
        "            img = dataset.read(out_shape=(NUM_BANDS, IMG_SIZE, IMG_SIZE), resampling=Resampling.bilinear)\n",
        "            img = img.astype(np.float32) / 255.0  # Normalizar para [0,1]\n",
        "            imagens.append(np.transpose(img, (1, 2, 0)))  # Converter para (32,32,16)\n",
        "    return np.array(imagens)\n",
        "\n",
        "# ğŸ”¹ Carregar as imagens e dividir em treino/teste\n",
        "imagens = carregar_patches(arquivos_tiff)\n",
        "X_train, X_test = train_test_split(imagens, test_size=0.2, random_state=42)\n",
        "\n",
        "# ğŸ”¹ Criar o Autoencoder\n",
        "def criar_autoencoder():\n",
        "    input_img = keras.Input(shape=(IMG_SIZE, IMG_SIZE, NUM_BANDS))\n",
        "\n",
        "    # Encoder\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    encoded = layers.Flatten()(x)\n",
        "    encoded = layers.Dense(LATENT_DIM, activation='relu')(encoded)\n",
        "\n",
        "    # Decoder\n",
        "    x = layers.Dense(8 * 8 * 128, activation='relu')(encoded)\n",
        "    x = layers.Reshape((8, 8, 128))(x)\n",
        "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    decoded = layers.Conv2D(NUM_BANDS, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    autoencoder = keras.Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "# ğŸ”¹ Criar o modelo\n",
        "autoencoder = criar_autoencoder()\n",
        "\n",
        "# ğŸ”¹ Configurar callbacks para salvar checkpoints e logs\n",
        "checkpoint_path = os.path.join(pasta_checkpoint, \"autoencoder_best.h5\")\n",
        "csv_logger_path = os.path.join(pasta_logs, \"training_log.csv\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "csv_logger = CSVLogger(csv_logger_path, append=True)\n",
        "\n",
        "# ğŸ”¹ Treinar o Autoencoder\n",
        "history = autoencoder.fit(\n",
        "    X_train, X_train,\n",
        "    validation_data=(X_test, X_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[checkpoint, csv_logger]\n",
        ")\n",
        "\n",
        "# ğŸ”¹ Salvar logs de treinamento em um DataFrame\n",
        "df_logs = pd.read_csv(csv_logger_path)\n",
        "print(df_logs.tail())  # Mostrar Ãºltimas entradas\n",
        "\n",
        "# ğŸ”¹ Salvar modelo final\n",
        "modelo_final_path = os.path.join(pasta_checkpoint, \"autoencoder_final.h5\")\n",
        "autoencoder.save(modelo_final_path)\n",
        "\n",
        "print(f\"âœ… Treinamento concluÃ­do. Modelo salvo em: {modelo_final_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POF4TdEYjMe4",
        "outputId": "cb1fe828-ac6a-4324-b4d4-615ebf65ac6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.1322\n",
            "Epoch 1: val_loss improved from inf to 0.00435, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 285ms/step - loss: 0.1282 - val_loss: 0.0044\n",
            "Epoch 2/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0043\n",
            "Epoch 2: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 3/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0043\n",
            "Epoch 3: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 4/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 0.0043\n",
            "Epoch 4: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 282ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 5/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0043\n",
            "Epoch 5: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 230ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 6/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.0043\n",
            "Epoch 6: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 247ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 7/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0043\n",
            "Epoch 7: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 202ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 8/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 0.0043\n",
            "Epoch 8: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 291ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 9/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0043\n",
            "Epoch 9: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 209ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 10/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 0.0043\n",
            "Epoch 10: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 11/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.0043\n",
            "Epoch 11: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 241ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 12/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 0.0043\n",
            "Epoch 12: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 300ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 13/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0043\n",
            "Epoch 13: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 232ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 14/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0043\n",
            "Epoch 14: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 217ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 15/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 0.0043\n",
            "Epoch 15: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 16/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0043\n",
            "Epoch 16: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 17/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 0.0043\n",
            "Epoch 17: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 322ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 18/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0043\n",
            "Epoch 18: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 211ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 19/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - loss: 0.0043\n",
            "Epoch 19: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 328ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 20/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0044\n",
            "Epoch 20: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 21/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 0.0044\n",
            "Epoch 21: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 22/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0043\n",
            "Epoch 22: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 23/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 0.0043\n",
            "Epoch 23: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 24/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0044\n",
            "Epoch 24: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 248ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 25/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0044\n",
            "Epoch 25: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 26/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - loss: 0.0043\n",
            "Epoch 26: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 288ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 27/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 0.0043\n",
            "Epoch 27: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 251ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 28/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0043\n",
            "Epoch 28: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 215ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 29/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 0.0043\n",
            "Epoch 29: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 286ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 30/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0044\n",
            "Epoch 30: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 31/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 0.0044\n",
            "Epoch 31: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 290ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 32/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0043\n",
            "Epoch 32: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 33/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 0.0043\n",
            "Epoch 33: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 34/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0043\n",
            "Epoch 34: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 208ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 35/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 0.0043\n",
            "Epoch 35: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 301ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 36/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.0043\n",
            "Epoch 36: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 240ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 37/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0043\n",
            "Epoch 37: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 207ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 38/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.0043\n",
            "Epoch 38: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 254ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 39/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0044\n",
            "Epoch 39: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 243ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 40/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0043\n",
            "Epoch 40: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 41/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 0.0044\n",
            "Epoch 41: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 297ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 42/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0043\n",
            "Epoch 42: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 43/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0043\n",
            "Epoch 43: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 308ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 44/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0043\n",
            "Epoch 44: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 45/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 0.0043\n",
            "Epoch 45: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 274ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 46/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.0043\n",
            "Epoch 46: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 256ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 47/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0044\n",
            "Epoch 47: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 212ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 48/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0043\n",
            "Epoch 48: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 235ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 49/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - loss: 0.0043\n",
            "Epoch 49: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 253ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 50/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0043\n",
            "Epoch 50: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 214ms/step - loss: 0.0043 - val_loss: 0.0044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    epoch      loss  val_loss\n",
            "45     45  0.004342  0.004351\n",
            "46     46  0.004342  0.004351\n",
            "47     47  0.004342  0.004351\n",
            "48     48  0.004342  0.004351\n",
            "49     49  0.004342  0.004351\n",
            "âœ… Treinamento concluÃ­do. Modelo salvo em: /content/drive/MyDrive/Unb/Autoencoder_Checkpoints/autoencoder_final.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¹ Caminho do log salvo\n",
        "csv_logger_path = \"/content/drive/MyDrive/Unb/Autoencoder_Logs/training_log.csv\"\n",
        "\n",
        "# ğŸ”¹ Carregar log do treinamento\n",
        "df_logs = pd.read_csv(csv_logger_path)\n",
        "\n",
        "# ğŸ”¹ Exibir Ãºltimas 10 Ã©pocas formatadas\n",
        "df_resumo = df_logs[['epoch', 'loss', 'val_loss']].tail(10)\n",
        "df_resumo.columns = ['Ã‰poca', 'Loss Treino', 'Loss ValidaÃ§Ã£o']\n",
        "\n",
        "# ğŸ”¹ Ajustar casas decimais\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "\n",
        "# ğŸ”¹ Exibir tabela formatada\n",
        "print(df_resumo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbPY5IEvHm9o",
        "outputId": "1bc3982e-cb7f-48c1-ea2f-3777fd2735e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Ã‰poca  Loss Treino  Loss ValidaÃ§Ã£o\n",
            "40     40       0.0043          0.0044\n",
            "41     41       0.0043          0.0044\n",
            "42     42       0.0043          0.0044\n",
            "43     43       0.0043          0.0044\n",
            "44     44       0.0043          0.0044\n",
            "45     45       0.0043          0.0044\n",
            "46     46       0.0043          0.0044\n",
            "47     47       0.0043          0.0044\n",
            "48     48       0.0043          0.0044\n",
            "49     49       0.0043          0.0044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho da pasta com os patches\n",
        "pasta_patches = \"/content/drive/MyDrive/Unb/Plantio_direto/Patches_32x32\"\n",
        "\n",
        "# Lista de arquivos\n",
        "arquivos_tiff = [os.path.join(pasta_patches, f) for f in os.listdir(pasta_patches) if f.endswith(\".tif\") or f.endswith(\".tiff\")]\n",
        "\n",
        "# Seleciona um subconjunto pequeno para anÃ¡lise (por exemplo, 10 arquivos)\n",
        "amostra_patches = np.random.choice(arquivos_tiff, min(10, len(arquivos_tiff)), replace=False)\n",
        "\n",
        "# Criar dataframe para armazenar estatÃ­sticas\n",
        "estatisticas = []\n",
        "\n",
        "for tiff_path in amostra_patches:\n",
        "    with rasterio.open(tiff_path) as dataset:\n",
        "        num_bandas = dataset.count\n",
        "        for i in range(1, num_bandas + 1):\n",
        "            banda = dataset.read(i).astype(np.float32).flatten()\n",
        "            estatisticas.append({\n",
        "                \"Arquivo\": os.path.basename(tiff_path),\n",
        "                \"Banda\": i,\n",
        "                \"MÃ­nimo\": np.min(banda),\n",
        "                \"MÃ¡ximo\": np.max(banda),\n",
        "                \"MÃ©dia\": np.mean(banda),\n",
        "                \"Desvio PadrÃ£o\": np.std(banda)\n",
        "            })\n",
        "\n",
        "# Criar DataFrame com os resultados\n",
        "df_estatisticas = pd.DataFrame(estatisticas)\n",
        "print(df_estatisticas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM8jh_JxjPI-",
        "outputId": "004a69ef-0748-45fb-85a0-15edfda1c2cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Arquivo  Banda    MÃ­nimo    MÃ¡ximo     MÃ©dia  Desvio PadrÃ£o\n",
            "0    patch_221.tif      1  0.118566  0.129346  0.124402       0.002352\n",
            "1    patch_221.tif      2  0.101213  0.113435  0.107760       0.002404\n",
            "2    patch_221.tif      3  0.096277  0.110978  0.103410       0.002844\n",
            "3    patch_221.tif      4  0.121103  0.161957  0.133440       0.006797\n",
            "4    patch_221.tif      5  0.216456  0.259050  0.234366       0.007746\n",
            "..             ...    ...       ...       ...       ...            ...\n",
            "155  patch_485.tif     12  0.143933  0.329623  0.192626       0.039964\n",
            "156  patch_485.tif     13  0.087473  0.236057  0.126215       0.030779\n",
            "157  patch_485.tif     14 -0.400389 -0.263387 -0.312824       0.026671\n",
            "158  patch_485.tif     15 -0.410041 -0.287266 -0.354499       0.024116\n",
            "159  patch_485.tif     16  0.063471  0.163519  0.089393       0.020453\n",
            "\n",
            "[160 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tiff_path = \"/content/drive/MyDrive/Unb/Plantio_direto/Patches_32x32/patch_485.tif\"\n",
        "\n",
        "with rasterio.open(tiff_path) as dataset:\n",
        "    num_bandas = dataset.count  # NÃºmero total de bandas\n",
        "\n",
        "    for i in range(1, num_bandas + 1):\n",
        "        banda = dataset.read(i).astype(np.float32)  # Ler cada banda\n",
        "        min_val, max_val = np.nanpercentile(banda, [1, 99])\n",
        "        banda_normalizada = np.clip((banda - min_val) / (max_val - min_val + 1e-6), 0, 1)\n",
        "\n",
        "        print(f\"Banda {i}: Min={banda_normalizada.min():.4f}, Max={banda_normalizada.max():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMfEtWZDlo9D",
        "outputId": "5dc8419b-4bb1-4fa2-f881-dfca64424605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Banda 1: Min=0.0000, Max=1.0000\n",
            "Banda 2: Min=0.0000, Max=1.0000\n",
            "Banda 3: Min=0.0000, Max=1.0000\n",
            "Banda 4: Min=0.0000, Max=1.0000\n",
            "Banda 5: Min=0.0000, Max=1.0000\n",
            "Banda 6: Min=0.0000, Max=1.0000\n",
            "Banda 7: Min=0.0000, Max=1.0000\n",
            "Banda 8: Min=0.0000, Max=1.0000\n",
            "Banda 9: Min=0.0000, Max=1.0000\n",
            "Banda 10: Min=0.0000, Max=1.0000\n",
            "Banda 11: Min=0.0000, Max=1.0000\n",
            "Banda 12: Min=0.0000, Max=1.0000\n",
            "Banda 13: Min=0.0000, Max=1.0000\n",
            "Banda 14: Min=0.0000, Max=1.0000\n",
            "Banda 15: Min=0.0000, Max=1.0000\n",
            "Banda 16: Min=0.0000, Max=1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from rasterio.enums import Resampling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "\n",
        "# ğŸ“Œ Configurar caminhos no Google Drive\n",
        "pasta_patches = \"/content/drive/MyDrive/Unb/Plantio_direto/Patches_32x32\"\n",
        "pasta_checkpoint = \"/content/drive/MyDrive/Unb/Autoencoder_Checkpoints_2\"\n",
        "pasta_logs = \"/content/drive/MyDrive/Unb/Autoencoder_Logs_2\"\n",
        "\n",
        "# Criar diretÃ³rios, se nÃ£o existirem\n",
        "os.makedirs(pasta_checkpoint, exist_ok=True)\n",
        "os.makedirs(pasta_logs, exist_ok=True)\n",
        "\n",
        "# ğŸ”¹ Definir os hiperparÃ¢metros\n",
        "IMG_SIZE = 32\n",
        "NUM_BANDS = 16  # 16 bandas espectrais\n",
        "LATENT_DIM = 128  # DimensÃ£o do espaÃ§o latente\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "\n",
        "# ğŸ”¹ Listar arquivos TIFF na pasta\n",
        "arquivos_tiff = [os.path.join(pasta_patches, f) for f in os.listdir(pasta_patches) if f.endswith(\".tif\")]\n",
        "\n",
        "# ğŸ”¹ FunÃ§Ã£o para carregar imagens TIFF como arrays normalizados\n",
        "def carregar_patches(arquivos_tiff):\n",
        "    imagens = []\n",
        "    for arquivo in arquivos_tiff:\n",
        "        with rasterio.open(arquivo) as dataset:\n",
        "            img = dataset.read(out_shape=(NUM_BANDS, IMG_SIZE, IMG_SIZE), resampling=Resampling.bilinear)\n",
        "            img = img.astype(np.float32)\n",
        "            img = np.transpose(img, (1, 2, 0))  # Converter para (32,32,16)\n",
        "            imagens.append(img)\n",
        "    return np.array(imagens)\n",
        "\n",
        "# ğŸ”¹ Carregar as imagens e dividir em treino/teste\n",
        "imagens = carregar_patches(arquivos_tiff)\n",
        "X_train, X_test = train_test_split(imagens, test_size=0.2, random_state=42)\n",
        "\n",
        "# ğŸ”¹ Criar o Autoencoder com NormalizaÃ§Ã£o e Camada Adicional\n",
        "def criar_autoencoder():\n",
        "    input_img = keras.Input(shape=(IMG_SIZE, IMG_SIZE, NUM_BANDS))\n",
        "\n",
        "    # ğŸ”¹ NormalizaÃ§Ã£o\n",
        "    x = layers.LayerNormalization()(input_img)  # Normaliza as bandas espectrais antes da convoluÃ§Ã£o\n",
        "\n",
        "    # ğŸ”¹ Encoder (Ajustado)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)  # â¬…ï¸ **Nova camada**\n",
        "    encoded = layers.Flatten()(x)\n",
        "    encoded = layers.Dense(LATENT_DIM, activation='relu')(encoded)\n",
        "\n",
        "    # ğŸ”¹ Decoder (Ajustado)\n",
        "    x = layers.Dense(8 * 8 * 256, activation='relu')(encoded)  # Correspondendo ao novo encoder\n",
        "    x = layers.Reshape((8, 8, 256))(x)\n",
        "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    decoded = layers.Conv2D(NUM_BANDS, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    autoencoder = keras.Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "# ğŸ”¹ Criar o modelo\n",
        "autoencoder = criar_autoencoder()\n",
        "\n",
        "# ğŸ”¹ Configurar callbacks para salvar checkpoints e logs\n",
        "checkpoint_path = os.path.join(pasta_checkpoint, \"autoencoder_best.h5\")\n",
        "csv_logger_path = os.path.join(pasta_logs, \"training_log.csv\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "csv_logger = CSVLogger(csv_logger_path, append=True)\n",
        "\n",
        "# ğŸ”¹ Treinar o Autoencoder\n",
        "history = autoencoder.fit(\n",
        "    X_train, X_train,\n",
        "    validation_data=(X_test, X_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[checkpoint, csv_logger]\n",
        ")\n",
        "\n",
        "# ğŸ”¹ Salvar logs de treinamento em um DataFrame\n",
        "df_logs = pd.read_csv(csv_logger_path)\n",
        "print(df_logs.tail())  # Mostrar Ãºltimas entradas\n",
        "\n",
        "# ğŸ”¹ Salvar modelo final\n",
        "modelo_final_path = os.path.join(pasta_checkpoint, \"autoencoder_final.h5\")\n",
        "autoencoder.save(modelo_final_path)\n",
        "\n",
        "print(f\"âœ… Treinamento concluÃ­do. Modelo salvo em: {modelo_final_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Hc0fhjtfF8X1",
        "outputId": "0f8c423c-79c8-4e97-f395-dc6f1bc4e90f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - loss: 11377.3535\n",
            "Epoch 1: val_loss improved from inf to 11365.26172, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_2/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 696ms/step - loss: 11376.7949 - val_loss: 11365.2617\n",
            "Epoch 2/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - loss: 11360.5898\n",
            "Epoch 2: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 708ms/step - loss: 11360.6455 - val_loss: 11365.2617\n",
            "Epoch 3/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - loss: 11368.7100\n",
            "Epoch 3: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 515ms/step - loss: 11368.3389 - val_loss: 11365.2617\n",
            "Epoch 4/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610ms/step - loss: 11367.0576\n",
            "Epoch 4: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 689ms/step - loss: 11366.7725 - val_loss: 11365.2617\n",
            "Epoch 5/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step - loss: 11362.5498\n",
            "Epoch 5: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 697ms/step - loss: 11362.5029 - val_loss: 11365.2617\n",
            "Epoch 6/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - loss: 11357.3496\n",
            "Epoch 6: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 502ms/step - loss: 11357.5762 - val_loss: 11365.2617\n",
            "Epoch 7/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512ms/step - loss: 11360.3252\n",
            "Epoch 7: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 589ms/step - loss: 11360.3955 - val_loss: 11365.2617\n",
            "Epoch 8/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - loss: 11359.3232\n",
            "Epoch 8: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 631ms/step - loss: 11359.4453 - val_loss: 11365.2617\n",
            "Epoch 9/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - loss: 11364.8730\n",
            "Epoch 9: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 493ms/step - loss: 11364.7041 - val_loss: 11365.2617\n",
            "Epoch 10/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - loss: 11364.1162\n",
            "Epoch 10: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 561ms/step - loss: 11363.9863 - val_loss: 11365.2617\n",
            "Epoch 11/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step - loss: 11365.9268\n",
            "Epoch 11: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 650ms/step - loss: 11365.7012 - val_loss: 11365.2617\n",
            "Epoch 12/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - loss: 11364.5029\n",
            "Epoch 12: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 544ms/step - loss: 11364.3525 - val_loss: 11365.2617\n",
            "Epoch 13/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - loss: 11365.9590\n",
            "Epoch 13: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 675ms/step - loss: 11365.7324 - val_loss: 11365.2617\n",
            "Epoch 14/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - loss: 11363.3906\n",
            "Epoch 14: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 533ms/step - loss: 11363.2988 - val_loss: 11365.2617\n",
            "Epoch 15/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - loss: 11370.1094\n",
            "Epoch 15: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 573ms/step - loss: 11369.6641 - val_loss: 11365.2617\n",
            "Epoch 16/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - loss: 11358.5840\n",
            "Epoch 16: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 982ms/step - loss: 11358.7451 - val_loss: 11365.2617\n",
            "Epoch 17/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596ms/step - loss: 11355.8691\n",
            "Epoch 17: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 636ms/step - loss: 11356.1738 - val_loss: 11365.2617\n",
            "Epoch 18/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - loss: 11360.7842\n",
            "Epoch 18: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 558ms/step - loss: 11360.8301 - val_loss: 11365.2617\n",
            "Epoch 19/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - loss: 11352.7676\n",
            "Epoch 19: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 540ms/step - loss: 11353.2354 - val_loss: 11365.2617\n",
            "Epoch 20/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665ms/step - loss: 11363.3340\n",
            "Epoch 20: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 742ms/step - loss: 11363.2451 - val_loss: 11365.2617\n",
            "Epoch 21/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517ms/step - loss: 11362.8203\n",
            "Epoch 21: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 557ms/step - loss: 11362.7588 - val_loss: 11365.2617\n",
            "Epoch 22/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641ms/step - loss: 11363.9531\n",
            "Epoch 22: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 682ms/step - loss: 11363.8320 - val_loss: 11365.2617\n",
            "Epoch 23/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - loss: 11358.0273\n",
            "Epoch 23: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 582ms/step - loss: 11358.2188 - val_loss: 11365.2617\n",
            "Epoch 24/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791ms/step - loss: 11361.8447\n",
            "Epoch 24: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 871ms/step - loss: 11361.8350 - val_loss: 11365.2617\n",
            "Epoch 25/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703ms/step - loss: 11363.8643\n",
            "Epoch 25: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 873ms/step - loss: 11363.7480 - val_loss: 11365.2617\n",
            "Epoch 26/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - loss: 11359.6914\n",
            "Epoch 26: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 672ms/step - loss: 11359.7949 - val_loss: 11365.2617\n",
            "Epoch 27/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575ms/step - loss: 11365.9805\n",
            "Epoch 27: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 614ms/step - loss: 11365.7529 - val_loss: 11365.2617\n",
            "Epoch 28/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - loss: 11358.4209\n",
            "Epoch 28: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 605ms/step - loss: 11358.5908 - val_loss: 11365.2617\n",
            "Epoch 29/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606ms/step - loss: 11356.1826\n",
            "Epoch 29: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 684ms/step - loss: 11356.4707 - val_loss: 11365.2617\n",
            "Epoch 30/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - loss: 11360.9805\n",
            "Epoch 30: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 549ms/step - loss: 11361.0156 - val_loss: 11365.2617\n",
            "Epoch 31/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - loss: 11356.6055\n",
            "Epoch 31: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 663ms/step - loss: 11356.8711 - val_loss: 11365.2617\n",
            "Epoch 32/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - loss: 11362.5732\n",
            "Epoch 32: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 593ms/step - loss: 11362.5244 - val_loss: 11365.2617\n",
            "Epoch 33/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625ms/step - loss: 11363.1982\n",
            "Epoch 33: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 667ms/step - loss: 11363.1172 - val_loss: 11365.2617\n",
            "Epoch 34/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - loss: 11361.5879\n",
            "Epoch 34: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 555ms/step - loss: 11361.5908 - val_loss: 11365.2617\n",
            "Epoch 35/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - loss: 11363.7129\n",
            "Epoch 35: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 582ms/step - loss: 11363.6045 - val_loss: 11365.2617\n",
            "Epoch 36/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610ms/step - loss: 11358.5146\n",
            "Epoch 36: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 689ms/step - loss: 11358.6797 - val_loss: 11365.2617\n",
            "Epoch 37/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - loss: 11364.2520\n",
            "Epoch 37: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 534ms/step - loss: 11364.1152 - val_loss: 11365.2617\n",
            "Epoch 38/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - loss: 11364.5078\n",
            "Epoch 38: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 538ms/step - loss: 11364.3574 - val_loss: 11365.2617\n",
            "Epoch 39/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586ms/step - loss: 11359.4863\n",
            "Epoch 39: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 628ms/step - loss: 11359.5996 - val_loss: 11365.2617\n",
            "Epoch 40/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541ms/step - loss: 11366.4355\n",
            "Epoch 40: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 620ms/step - loss: 11366.1846 - val_loss: 11365.2617\n",
            "Epoch 41/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - loss: 11362.1387\n",
            "Epoch 41: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 563ms/step - loss: 11362.1133 - val_loss: 11365.2617\n",
            "Epoch 42/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - loss: 11367.3105\n",
            "Epoch 42: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 673ms/step - loss: 11367.0127 - val_loss: 11365.2617\n",
            "Epoch 43/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - loss: 11362.6338\n",
            "Epoch 43: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 595ms/step - loss: 11362.5820 - val_loss: 11365.2617\n",
            "Epoch 44/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - loss: 11364.0127\n",
            "Epoch 44: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 547ms/step - loss: 11363.8877 - val_loss: 11365.2617\n",
            "Epoch 45/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - loss: 11366.7148\n",
            "Epoch 45: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 665ms/step - loss: 11366.4482 - val_loss: 11365.2617\n",
            "Epoch 46/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - loss: 11359.9170\n",
            "Epoch 46: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 565ms/step - loss: 11360.0088 - val_loss: 11365.2617\n",
            "Epoch 47/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580ms/step - loss: 11361.7363\n",
            "Epoch 47: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 657ms/step - loss: 11361.7324 - val_loss: 11365.2617\n",
            "Epoch 48/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622ms/step - loss: 11361.6562\n",
            "Epoch 48: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 699ms/step - loss: 11361.6562 - val_loss: 11365.2617\n",
            "Epoch 49/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - loss: 11365.9453\n",
            "Epoch 49: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 615ms/step - loss: 11365.7188 - val_loss: 11365.2617\n",
            "Epoch 50/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606ms/step - loss: 11360.2695\n",
            "Epoch 50: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 686ms/step - loss: 11360.3418 - val_loss: 11365.2617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    epoch          loss      val_loss\n",
            "45     45  11361.653320  11365.261719\n",
            "46     46  11361.653320  11365.261719\n",
            "47     47  11361.653320  11365.261719\n",
            "48     48  11361.652344  11365.261719\n",
            "49     49  11361.653320  11365.261719\n",
            "âœ… Treinamento concluÃ­do. Modelo salvo em: /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_2/autoencoder_final.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¹ Caminho do log salvo\n",
        "csv_logger_path = \"/content/drive/MyDrive/Unb/Autoencoder_Logs_2/training_log.csv\"\n",
        "\n",
        "# ğŸ”¹ Carregar log do treinamento\n",
        "df_logs = pd.read_csv(csv_logger_path)\n",
        "\n",
        "# ğŸ”¹ Exibir Ãºltimas 10 Ã©pocas formatadas\n",
        "df_resumo = df_logs[['epoch', 'loss', 'val_loss']].tail(10)\n",
        "df_resumo.columns = ['Ã‰poca', 'Loss Treino', 'Loss ValidaÃ§Ã£o']\n",
        "\n",
        "# ğŸ”¹ Ajustar casas decimais\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "\n",
        "# ğŸ”¹ Exibir tabela formatada\n",
        "print(df_resumo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhctlNPWHsmR",
        "outputId": "8f402f8c-4fcb-4768-b01a-fd23663b5b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Ã‰poca  Loss Treino  Loss ValidaÃ§Ã£o\n",
            "40     40   11361.6533      11365.2617\n",
            "41     41   11361.6523      11365.2617\n",
            "42     42   11361.6533      11365.2617\n",
            "43     43   11361.6523      11365.2617\n",
            "44     44   11361.6543      11365.2617\n",
            "45     45   11361.6533      11365.2617\n",
            "46     46   11361.6533      11365.2617\n",
            "47     47   11361.6533      11365.2617\n",
            "48     48   11361.6523      11365.2617\n",
            "49     49   11361.6533      11365.2617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from rasterio.enums import Resampling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau\n",
        "\n",
        "# ğŸ“Œ Caminhos no Google Drive\n",
        "pasta_patches = \"/content/drive/MyDrive/Unb/Plantio_direto/Patches_32x32\"\n",
        "pasta_checkpoint = \"/content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3\"\n",
        "pasta_logs = \"/content/drive/MyDrive/Unb/Autoencoder_Logs_3\"\n",
        "\n",
        "# Criar diretÃ³rios, se nÃ£o existirem\n",
        "os.makedirs(pasta_checkpoint, exist_ok=True)\n",
        "os.makedirs(pasta_logs, exist_ok=True)\n",
        "\n",
        "# ğŸ”¹ HiperparÃ¢metros\n",
        "IMG_SIZE = 32\n",
        "NUM_BANDS = 16\n",
        "LATENT_DIM = 128\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "\n",
        "# ğŸ”¹ Normalizador global para os patches\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# ğŸ”¹ FunÃ§Ã£o para carregar e normalizar imagens TIFF\n",
        "def carregar_patches(arquivos_tiff):\n",
        "    imagens = []\n",
        "    for arquivo in arquivos_tiff:\n",
        "        with rasterio.open(arquivo) as dataset:\n",
        "            img = dataset.read(out_shape=(NUM_BANDS, IMG_SIZE, IMG_SIZE), resampling=Resampling.bilinear)\n",
        "            img = img.astype(np.float32)\n",
        "            img = np.transpose(img, (1, 2, 0))  # (32,32,16)\n",
        "\n",
        "            # ğŸ”¹ Normalizar valores (MinMaxScaler)\n",
        "            img = img.reshape(-1, NUM_BANDS)\n",
        "            img = scaler.fit_transform(img)  # Normalizar entre 0 e 1\n",
        "            img = img.reshape(IMG_SIZE, IMG_SIZE, NUM_BANDS)\n",
        "\n",
        "            imagens.append(img)\n",
        "\n",
        "    return np.array(imagens)\n",
        "\n",
        "# ğŸ”¹ Carregar imagens e dividir em treino/teste\n",
        "arquivos_tiff = [os.path.join(pasta_patches, f) for f in os.listdir(pasta_patches) if f.endswith(\".tif\")]\n",
        "imagens = carregar_patches(arquivos_tiff)\n",
        "X_train, X_test = train_test_split(imagens, test_size=0.2, random_state=42)\n",
        "\n",
        "# ğŸ”¹ Criar o Autoencoder ajustado\n",
        "def criar_autoencoder():\n",
        "    input_img = keras.Input(shape=(IMG_SIZE, IMG_SIZE, NUM_BANDS))\n",
        "\n",
        "    # ğŸ”¹ Encoder (com BatchNormalization e Dropout)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.2)(x)  # ğŸ”¹ Dropout para regularizaÃ§Ã£o\n",
        "\n",
        "    encoded = layers.Flatten()(x)\n",
        "    encoded = layers.Dense(LATENT_DIM, activation='relu')(encoded)\n",
        "\n",
        "    # ğŸ”¹ Decoder\n",
        "    x = layers.Dense(8 * 8 * 128, activation='relu')(encoded)\n",
        "    x = layers.Reshape((8, 8, 128))(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "    decoded = layers.Conv2D(NUM_BANDS, (3, 3), activation='linear', padding='same')(x)  # ğŸ”¹ SaÃ­da com ativaÃ§Ã£o 'linear'\n",
        "\n",
        "    autoencoder = keras.Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005), loss='mse')  # ğŸ”¹ Reduzi taxa de aprendizado\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "# ğŸ”¹ Criar modelo\n",
        "autoencoder = criar_autoencoder()\n",
        "\n",
        "# ğŸ”¹ Callbacks (Salvar checkpoints, reduzir LR dinamicamente)\n",
        "checkpoint_path = os.path.join(pasta_checkpoint, \"autoencoder_best.h5\")\n",
        "csv_logger_path = os.path.join(pasta_logs, \"training_log.csv\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "csv_logger = CSVLogger(csv_logger_path, append=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# ğŸ”¹ Treinar o modelo\n",
        "history = autoencoder.fit(\n",
        "    X_train, X_train,\n",
        "    validation_data=(X_test, X_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[checkpoint, csv_logger, reduce_lr]\n",
        ")\n",
        "\n",
        "# ğŸ”¹ Salvar logs do treinamento\n",
        "df_logs = pd.read_csv(csv_logger_path)\n",
        "print(df_logs.tail())\n",
        "\n",
        "# ğŸ”¹ Salvar modelo final\n",
        "modelo_final_path = os.path.join(pasta_checkpoint, \"autoencoder_final.h5\")\n",
        "autoencoder.save(modelo_final_path)\n",
        "\n",
        "print(f\"âœ… Treinamento concluÃ­do. Modelo salvo em: {modelo_final_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZEKLRq2HGkC",
        "outputId": "1d743f1e-e5c2-4bd8-8090-dd8f7ebb8353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 0.1789\n",
            "Epoch 1: val_loss improved from inf to 0.23799, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 331ms/step - loss: 0.1757 - val_loss: 0.2380 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - loss: 0.0633\n",
            "Epoch 2: val_loss improved from 0.23799 to 0.20697, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 381ms/step - loss: 0.0632 - val_loss: 0.2070 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.0484\n",
            "Epoch 3: val_loss improved from 0.20697 to 0.17141, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 270ms/step - loss: 0.0483 - val_loss: 0.1714 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 0.0401\n",
            "Epoch 4: val_loss improved from 0.17141 to 0.14583, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 324ms/step - loss: 0.0401 - val_loss: 0.1458 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 0.0351\n",
            "Epoch 5: val_loss improved from 0.14583 to 0.12922, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 297ms/step - loss: 0.0351 - val_loss: 0.1292 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0319\n",
            "Epoch 6: val_loss improved from 0.12922 to 0.11747, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 247ms/step - loss: 0.0319 - val_loss: 0.1175 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 0.0312\n",
            "Epoch 7: val_loss improved from 0.11747 to 0.10185, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 268ms/step - loss: 0.0312 - val_loss: 0.1019 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - loss: 0.0284\n",
            "Epoch 8: val_loss improved from 0.10185 to 0.09249, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 375ms/step - loss: 0.0284 - val_loss: 0.0925 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0272\n",
            "Epoch 9: val_loss improved from 0.09249 to 0.07913, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 248ms/step - loss: 0.0272 - val_loss: 0.0791 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 0.0274\n",
            "Epoch 10: val_loss improved from 0.07913 to 0.07864, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 328ms/step - loss: 0.0274 - val_loss: 0.0786 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.0260\n",
            "Epoch 11: val_loss improved from 0.07864 to 0.06875, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 283ms/step - loss: 0.0260 - val_loss: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - loss: 0.0249\n",
            "Epoch 12: val_loss improved from 0.06875 to 0.06350, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 359ms/step - loss: 0.0248 - val_loss: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.0241\n",
            "Epoch 13: val_loss improved from 0.06350 to 0.05650, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 273ms/step - loss: 0.0241 - val_loss: 0.0565 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - loss: 0.0239\n",
            "Epoch 14: val_loss did not improve from 0.05650\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 375ms/step - loss: 0.0239 - val_loss: 0.0596 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - loss: 0.0221\n",
            "Epoch 15: val_loss improved from 0.05650 to 0.05518, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - loss: 0.0221 - val_loss: 0.0552 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 0.0216\n",
            "Epoch 16: val_loss did not improve from 0.05518\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 332ms/step - loss: 0.0216 - val_loss: 0.0553 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - loss: 0.0213\n",
            "Epoch 17: val_loss improved from 0.05518 to 0.04999, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 352ms/step - loss: 0.0213 - val_loss: 0.0500 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 0.0205\n",
            "Epoch 18: val_loss improved from 0.04999 to 0.04417, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 303ms/step - loss: 0.0205 - val_loss: 0.0442 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - loss: 0.0202\n",
            "Epoch 19: val_loss improved from 0.04417 to 0.03920, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 412ms/step - loss: 0.0202 - val_loss: 0.0392 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 0.0201\n",
            "Epoch 20: val_loss did not improve from 0.03920\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 261ms/step - loss: 0.0201 - val_loss: 0.0435 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - loss: 0.0196\n",
            "Epoch 21: val_loss improved from 0.03920 to 0.03562, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 386ms/step - loss: 0.0195 - val_loss: 0.0356 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 0.0183\n",
            "Epoch 22: val_loss improved from 0.03562 to 0.03400, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 264ms/step - loss: 0.0183 - val_loss: 0.0340 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - loss: 0.0177\n",
            "Epoch 23: val_loss improved from 0.03400 to 0.02911, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 377ms/step - loss: 0.0177 - val_loss: 0.0291 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0180\n",
            "Epoch 24: val_loss did not improve from 0.02911\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 247ms/step - loss: 0.0180 - val_loss: 0.0356 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - loss: 0.0177\n",
            "Epoch 25: val_loss did not improve from 0.02911\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 281ms/step - loss: 0.0178 - val_loss: 0.0304 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 0.0178\n",
            "Epoch 26: val_loss did not improve from 0.02911\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 310ms/step - loss: 0.0178 - val_loss: 0.0324 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0184\n",
            "Epoch 27: val_loss did not improve from 0.02911\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 228ms/step - loss: 0.0184 - val_loss: 0.0296 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 0.0171\n",
            "Epoch 28: val_loss did not improve from 0.02911\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 299ms/step - loss: 0.0171 - val_loss: 0.0385 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 0.0190\n",
            "Epoch 29: val_loss improved from 0.02911 to 0.02689, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 286ms/step - loss: 0.0189 - val_loss: 0.0269 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - loss: 0.0159\n",
            "Epoch 30: val_loss improved from 0.02689 to 0.02509, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 365ms/step - loss: 0.0159 - val_loss: 0.0251 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.0153\n",
            "Epoch 31: val_loss did not improve from 0.02509\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - loss: 0.0153 - val_loss: 0.0264 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0149\n",
            "Epoch 32: val_loss improved from 0.02509 to 0.02509, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 428ms/step - loss: 0.0149 - val_loss: 0.0251 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0146\n",
            "Epoch 33: val_loss did not improve from 0.02509\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 247ms/step - loss: 0.0146 - val_loss: 0.0252 - learning_rate: 2.5000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - loss: 0.0143\n",
            "Epoch 34: val_loss improved from 0.02509 to 0.02456, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 376ms/step - loss: 0.0143 - val_loss: 0.0246 - learning_rate: 2.5000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.0141\n",
            "Epoch 35: val_loss improved from 0.02456 to 0.02325, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 252ms/step - loss: 0.0141 - val_loss: 0.0232 - learning_rate: 2.5000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - loss: 0.0141\n",
            "Epoch 36: val_loss improved from 0.02325 to 0.02306, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 377ms/step - loss: 0.0141 - val_loss: 0.0231 - learning_rate: 2.5000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 0.0142\n",
            "Epoch 37: val_loss improved from 0.02306 to 0.02272, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 289ms/step - loss: 0.0142 - val_loss: 0.0227 - learning_rate: 2.5000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - loss: 0.0135\n",
            "Epoch 38: val_loss improved from 0.02272 to 0.02246, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 382ms/step - loss: 0.0135 - val_loss: 0.0225 - learning_rate: 2.5000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0136\n",
            "Epoch 39: val_loss did not improve from 0.02246\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 235ms/step - loss: 0.0136 - val_loss: 0.0236 - learning_rate: 2.5000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 0.0135\n",
            "Epoch 40: val_loss improved from 0.02246 to 0.02164, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - loss: 0.0135 - val_loss: 0.0216 - learning_rate: 2.5000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - loss: 0.0135\n",
            "Epoch 41: val_loss did not improve from 0.02164\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 256ms/step - loss: 0.0135 - val_loss: 0.0220 - learning_rate: 2.5000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 0.0131\n",
            "Epoch 42: val_loss did not improve from 0.02164\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 331ms/step - loss: 0.0131 - val_loss: 0.0226 - learning_rate: 2.5000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.0131\n",
            "Epoch 43: val_loss did not improve from 0.02164\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 251ms/step - loss: 0.0131 - val_loss: 0.0225 - learning_rate: 2.5000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - loss: 0.0134\n",
            "Epoch 44: val_loss did not improve from 0.02164\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 349ms/step - loss: 0.0134 - val_loss: 0.0240 - learning_rate: 2.5000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.0134\n",
            "Epoch 45: val_loss improved from 0.02164 to 0.02142, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 280ms/step - loss: 0.0134 - val_loss: 0.0214 - learning_rate: 2.5000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - loss: 0.0130\n",
            "Epoch 46: val_loss did not improve from 0.02142\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 353ms/step - loss: 0.0130 - val_loss: 0.0217 - learning_rate: 2.5000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0125\n",
            "Epoch 47: val_loss improved from 0.02142 to 0.02106, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 264ms/step - loss: 0.0125 - val_loss: 0.0211 - learning_rate: 2.5000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - loss: 0.0126\n",
            "Epoch 48: val_loss did not improve from 0.02106\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 349ms/step - loss: 0.0126 - val_loss: 0.0215 - learning_rate: 2.5000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 0.0128\n",
            "Epoch 49: val_loss did not improve from 0.02106\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 249ms/step - loss: 0.0128 - val_loss: 0.0214 - learning_rate: 2.5000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - loss: 0.0124\n",
            "Epoch 50: val_loss did not improve from 0.02106\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 358ms/step - loss: 0.0124 - val_loss: 0.0218 - learning_rate: 2.5000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    epoch      loss  val_loss\n",
            "45     45  0.012904  0.021734\n",
            "46     46  0.012613  0.021057\n",
            "47     47  0.012525  0.021512\n",
            "48     48  0.012638  0.021403\n",
            "49     49  0.012382  0.021758\n",
            "âœ… Treinamento concluÃ­do. Modelo salvo em: /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_final.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¹ Caminho do log salvo\n",
        "csv_logger_path = \"/content/drive/MyDrive/Unb/Autoencoder_Logs_3/training_log.csv\"\n",
        "\n",
        "# ğŸ”¹ Carregar log do treinamento\n",
        "df_logs = pd.read_csv(csv_logger_path)\n",
        "\n",
        "# ğŸ”¹ Exibir Ãºltimas 10 Ã©pocas formatadas\n",
        "df_resumo = df_logs[['epoch', 'loss', 'val_loss']].tail(10)\n",
        "df_resumo.columns = ['Ã‰poca', 'Loss Treino', 'Loss ValidaÃ§Ã£o']\n",
        "\n",
        "# ğŸ”¹ Ajustar casas decimais\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "\n",
        "# ğŸ”¹ Exibir tabela formatada\n",
        "print(df_resumo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bKVk0ScHvsG",
        "outputId": "3c373a27-c204-49a5-8aad-63c6f3488fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Ã‰poca  Loss Treino  Loss ValidaÃ§Ã£o\n",
            "40     40       0.0133          0.0220\n",
            "41     41       0.0131          0.0226\n",
            "42     42       0.0132          0.0225\n",
            "43     43       0.0136          0.0240\n",
            "44     44       0.0132          0.0214\n",
            "45     45       0.0129          0.0217\n",
            "46     46       0.0126          0.0211\n",
            "47     47       0.0125          0.0215\n",
            "48     48       0.0126          0.0214\n",
            "49     49       0.0124          0.0218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow.keras.losses\n",
        "\n",
        "# ğŸ”¹ Caminho do modelo treinado e de um patch de exemplo\n",
        "model_path = \"/content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_final.h5\"\n",
        "sample_image_path = \"/content/drive/MyDrive/Unb/Plantio_direto/Patches_32x32/patch_302.tif\"\n",
        "\n",
        "\n",
        "# Registrar manualmente a mÃ©trica MSE\n",
        "custom_objects = {\"mse\": tensorflow.keras.losses.MeanSquaredError()}\n",
        "\n",
        "# Agora carregue o modelo com a mÃ©trica registrada\n",
        "autoencoder = load_model(model_path, custom_objects=custom_objects)\n",
        "\n",
        "\n",
        "# ğŸ”¹ FunÃ§Ã£o para normalizar imagem\n",
        "def normalize(img):\n",
        "    min_val, max_val = np.nanpercentile(img, [1, 99])\n",
        "    return np.clip((img - min_val) / (max_val - min_val + 1e-6), 0, 1)\n",
        "\n",
        "# ğŸ”¹ Carregar patch e processar\n",
        "with rasterio.open(sample_image_path) as dataset:\n",
        "    img = dataset.read().astype(np.float32)  # (C, H, W)\n",
        "    img_rgb = np.stack([normalize(img[3]), normalize(img[2]), normalize(img[1])], axis=-1)  # Bandas 4,3,2 (RGB)\n",
        "    img_input = np.expand_dims(img, axis=0)  # Adiciona batch dimension\n",
        "    img_input = np.transpose(img_input, (0, 2, 3, 1))\n",
        "\n",
        "\n",
        "\n",
        "# ğŸ”¹ PrediÃ§Ã£o pelo autoencoder\n",
        "reconstructed = autoencoder.predict(img_input)\n",
        "reconstructed_rgb = np.stack([normalize(reconstructed[0, 3]), normalize(reconstructed[0, 2]), normalize(reconstructed[0, 1])], axis=-1)\n",
        "\n",
        "# ğŸ”¹ Definir classe atribuÃ­da (Exemplo: clustering)\n",
        "predicted_class = np.random.choice([\"Grupo 1\", \"Grupo 2\", \"Grupo 3\"])  # Substituir por classificaÃ§Ã£o real\n",
        "\n",
        "# ğŸ”¹ Visualizar resultados\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axes[0].imshow(img_rgb)\n",
        "axes[0].set_title(\"Imagem Original\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(reconstructed_rgb)\n",
        "axes[1].set_title(\"ReconstruÃ§Ã£o pelo Autoencoder\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "axes[2].text(0.5, 0.5, predicted_class, fontsize=20, ha='center', va='center', bbox=dict(facecolor='lightgray', edgecolor='black'))\n",
        "axes[2].set_title(\"Classe AtribuÃ­da\")\n",
        "axes[2].axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "zyW3zs_LLmU7",
        "outputId": "c8b15b4d-20c5-4036-8e0b-fde042ec45a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}