{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbQlXc87hi5U",
        "outputId": "6f634378-e309-44da-e531-af8389a1510f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.26.4)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.1)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n"
          ]
        }
      ],
      "source": [
        "# Conex√£o do Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Instala√ß√£o de biblioteca\n",
        "!pip install rasterio\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import rasterio\n",
        "from rasterio.enums import Resampling\n",
        "import numpy as np\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from rasterio.windows import Window\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import tensorflow\n",
        "import keras\n",
        "from rasterio.shutil import copy\n",
        "from rasterio.warp import transform\n",
        "\n",
        "#Declara√ß√£o de variaveis\n",
        "bs = \"/content/drive/MyDrive/Unb/Plantio_direto/Patches_32x32\"\n",
        "\n",
        "#Define fun√ß√µes\n",
        "def detalhes(tiff_path):\n",
        "    \"\"\"Exibe informa√ß√µes detalhadas sobre um arquivo TIFF geoespacial.\"\"\"\n",
        "    with rasterio.open(tiff_path) as dataset:\n",
        "        print(f\"üìÇ Arquivo: {tiff_path}\")\n",
        "        print(f\"‚û°Ô∏è CRS: {dataset.crs}\")  # Sistema de Coordenadas de Refer√™ncia\n",
        "        print(f\"‚û°Ô∏è Resolu√ß√£o: {dataset.res[0]}, {dataset.res[1]}\")  # Tamanho do pixel\n",
        "        print(f\"‚û°Ô∏è Dimens√µes: {dataset.width} x {dataset.height} (Largura x Altura)\")\n",
        "        print(f\"‚û°Ô∏è Quantidade de bandas: {dataset.count}\")\n",
        "        print(f\"‚û°Ô∏è Extens√£o: {dataset.bounds}\")  # Bounding box\n",
        "        print(f\"‚û°Ô∏è Tipo de dado das bandas: {[dataset.dtypes[i] for i in range(dataset.count)]}\")\n",
        "        print(f\"‚û°Ô∏è Perfil do dataset: {dataset.profile}\")  # Metadados gerais\n",
        "        print(f\"‚û°Ô∏è Transforma√ß√£o Afim (GeoTransform): {dataset.transform}\")  # Matriz de transforma√ß√£o espacial\n",
        "        print(f\"‚û°Ô∏è Valor NoData: {dataset.nodata}\")  # Valor que representa aus√™ncia de dados\n",
        "        print(f\"‚û°Ô∏è Metadata: {dataset.meta}\")  # Metadados completos\n",
        "\n",
        "#visualiza amostra do mapa\n",
        "def visualizar_tiff_reduzido(file_path, fator_reducao=10, cmap='gray', canal=1):\n",
        "    with rasterio.open(file_path) as src:\n",
        "        # Reduz a resolu√ß√£o da primeira banda\n",
        "        small_window = src.read(canal, out_shape=(src.height // fator_reducao, src.width // fator_reducao))\n",
        "        # Exibe a imagem reduzida\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.imshow(small_window, cmap=cmap)\n",
        "        # plt.colorbar()\n",
        "        plt.title(f\"Visualiza√ß√£o r√°pida do TIFF (reduzido {fator_reducao}x)\")\n",
        "        plt.show()\n",
        "\n",
        "def rgb(tiff_path, bandas_rgb=(4, 3, 2), gamma=1.2, percentil=(1, 99)):\n",
        "    \"\"\"\n",
        "    Exibe a composi√ß√£o RGB de um patch TIFF e imprime suas coordenadas geogr√°ficas.\n",
        "\n",
        "    Args:\n",
        "        tiff_path (str): Caminho do arquivo TIFF.\n",
        "        bandas_rgb (tuple): √çndices das bandas para o RGB (padr√£o: (4, 3, 2)).\n",
        "        gamma (float): Fator de corre√ß√£o gama para melhorar contraste.\n",
        "        percentil (tuple): Percentis para normaliza√ß√£o (padr√£o: 1% e 99%).\n",
        "    \"\"\"\n",
        "    with rasterio.open(tiff_path) as dataset:\n",
        "        if max(bandas_rgb) > dataset.count:\n",
        "            print(f\"Erro: O arquivo tem apenas {dataset.count} bandas.\")\n",
        "            return\n",
        "\n",
        "        # Ler as bandas RGB\n",
        "        r = dataset.read(bandas_rgb[0]).astype(np.float32)\n",
        "        g = dataset.read(bandas_rgb[1]).astype(np.float32)\n",
        "        b = dataset.read(bandas_rgb[2]).astype(np.float32)\n",
        "\n",
        "        # Normalizar usando percentis mais conservadores\n",
        "        def normalizar(banda):\n",
        "            min_val, max_val = np.nanpercentile(banda, percentil)\n",
        "            return np.clip((banda - min_val) / (max_val - min_val + 1e-6), 0, 1)\n",
        "\n",
        "        r, g, b = map(normalizar, [r, g, b])\n",
        "\n",
        "        # Aplicar corre√ß√£o gama\n",
        "        def corrigir_gamma(banda, gamma):\n",
        "            return np.power(banda, 1/gamma)\n",
        "\n",
        "        r, g, b = map(lambda x: corrigir_gamma(x, gamma), [r, g, b])\n",
        "\n",
        "        # Criar imagem RGB\n",
        "        rgb = np.dstack((r, g, b))\n",
        "\n",
        "        # Obter coordenadas geogr√°ficas do centro e cantos do patch\n",
        "        transform = dataset.transform\n",
        "        height, width = dataset.height, dataset.width\n",
        "\n",
        "        # Canto superior esquerdo\n",
        "        lon1, lat1 = rasterio.transform.xy(transform, 0, 0)\n",
        "        # Canto inferior direito\n",
        "        lon2, lat2 = rasterio.transform.xy(transform, height - 1, width - 1)\n",
        "        # Centro do patch\n",
        "        center_x, center_y = width // 2, height // 2\n",
        "        lon_c, lat_c = rasterio.transform.xy(transform, center_y, center_x)\n",
        "\n",
        "        # Verificar se a proje√ß√£o √© geogr√°fica (lat/lon)\n",
        "        if dataset.crs and dataset.crs.to_epsg() not in [4326]:  # Se n√£o for WGS 84\n",
        "            from rasterio.warp import transform\n",
        "            lon1, lat1 = transform(dataset.crs, 'EPSG:4326', [lon1], [lat1])\n",
        "            lon2, lat2 = transform(dataset.crs, 'EPSG:4326', [lon2], [lat2])\n",
        "            lon_c, lat_c = transform(dataset.crs, 'EPSG:4326', [lon_c], [lat_c])\n",
        "            lon1, lat1, lon2, lat2, lon_c, lat_c = lon1[0], lat1[0], lon2[0], lat2[0], lon_c[0], lat_c[0]\n",
        "\n",
        "        # Exibir coordenadas geogr√°ficas\n",
        "        print(f\"üìç Coordenadas do patch:\")\n",
        "        print(f\"   Superior Esquerdo:  ({lat1:.6f}, {lon1:.6f})\")\n",
        "        print(f\"   Inferior Direito:   ({lat2:.6f}, {lon2:.6f})\")\n",
        "        print(f\"   Centro:             ({lat_c:.6f}, {lon_c:.6f})\")\n",
        "\n",
        "        # Exibir a imagem RGB\n",
        "        plt.figure(figsize=(5, 5))\n",
        "        plt.imshow(rgb)\n",
        "        plt.title(f\"Composi√ß√£o RGB - ({lat_c:.6f}, {lon_c:.6f})\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def analisar_patch(tiff_path, banda=18):\n",
        "    \"\"\"\n",
        "    Analisa um patch TIFF e exibe estat√≠sticas da banda selecionada.\n",
        "\n",
        "    Args:\n",
        "        tiff_path (str): Caminho do arquivo TIFF.\n",
        "        banda (int): √çndice da banda a ser analisada (padr√£o: 18).\n",
        "    \"\"\"\n",
        "    if not os.path.exists(tiff_path):\n",
        "        print(f\"Arquivo n√£o encontrado: {tiff_path}\")\n",
        "        return\n",
        "\n",
        "    with rasterio.open(tiff_path) as dataset:\n",
        "        if banda > dataset.count:\n",
        "            print(f\"O arquivo tem apenas {dataset.count} bandas. A banda {banda} n√£o existe.\")\n",
        "            return\n",
        "\n",
        "        banda_18 = dataset.read(banda).astype(np.float32)  # Ler banda 18 como float\n",
        "\n",
        "        # Exibir estat√≠sticas\n",
        "        print(f\"üìÇ Analisando: {tiff_path}\")\n",
        "        print(f\"üìè Dimens√µes: {banda_18.shape}\")\n",
        "        print(f\"‚ö´ Valor NoData do TIFF: {dataset.nodata}\")\n",
        "        print(f\"üî¢ Valores √∫nicos: {np.unique(banda_18)}\")\n",
        "        print(f\"üîç M√≠nimo: {np.min(banda_18)}, M√°ximo: {np.max(banda_18)}\")\n",
        "        print(f\"üìä M√©dia: {np.mean(banda_18)}, Desvio padr√£o: {np.std(banda_18)}\")\n",
        "        print(f\"üõë Pixels exatamente 0.0: {np.sum(banda_18 == 0.0)} / {banda_18.size}\")\n",
        "        print(f\"üöÄ Pixels exatamente 1.0: {np.sum(banda_18 == 1.0)} / {banda_18.size}\")\n",
        "        print(f\"‚ùì Pixels NaN: {np.sum(np.isnan(banda_18))}\")\n",
        "\n",
        "        # Visualizar a banda 18\n",
        "        import matplotlib.pyplot as plt\n",
        "        plt.imshow(banda_18, cmap=\"gray\")\n",
        "        plt.colorbar()\n",
        "        plt.title(\"Banda 18 - Patch analisado\")\n",
        "        plt.show()\n",
        "\n",
        "def visualizar_patch_aleatorio(pasta_patches):\n",
        "    \"\"\"\n",
        "    Seleciona aleatoriamente um arquivo TIFF da pasta e exibe suas bandas.\n",
        "\n",
        "    Args:\n",
        "        pasta_patches (str): Caminho da pasta contendo os patches TIFF.\n",
        "    \"\"\"\n",
        "    # Obter a lista de arquivos na pasta\n",
        "    arquivos_tiff = [f for f in os.listdir(pasta_patches) if f.endswith(\".tiff\") or f.endswith(\".tif\")]\n",
        "\n",
        "    # Verificar se h√° arquivos na pasta\n",
        "    if not arquivos_tiff:\n",
        "        print(\"Nenhum arquivo TIFF encontrado na pasta.\")\n",
        "        return\n",
        "\n",
        "    # Escolher um arquivo aleatoriamente\n",
        "    tiff_escolhido = random.choice(arquivos_tiff)\n",
        "    tiff_path = os.path.join(pasta_patches, tiff_escolhido)\n",
        "\n",
        "    print(f\"üìÇ Exibindo: {tiff_escolhido}\")\n",
        "\n",
        "    # Abrir o arquivo e exibir as descri√ß√µes das bandas\n",
        "    with rasterio.open(tiff_path) as dataset:\n",
        "        num_bands = dataset.count\n",
        "        fig, axes = plt.subplots(nrows=(num_bands // 5) + 1, ncols=5, figsize=(15, (num_bands // 5) * 3))\n",
        "\n",
        "        for i in range(num_bands):\n",
        "            band = dataset.read(i + 1).astype(np.float32)  # Lendo a banda (come√ßa do 1)\n",
        "\n",
        "            # Obter valores m√≠nimo e m√°ximo da banda\n",
        "            band_min, band_max = np.nanmin(band), np.nanmax(band)\n",
        "            print(f\"üìä Banda {i+1} - M√≠n: {band_min}, M√°x: {band_max}\")\n",
        "\n",
        "            # Evitar normaliza√ß√£o errada se a banda for constante\n",
        "            if band_max == band_min:\n",
        "                # band = np.zeros_like(band)  # Evita dividir por zero, mantendo preto\n",
        "                band = np.ones_like(band)  # Evita dividir por zero, mantendo branco\n",
        "            else:\n",
        "                band = (band - band_min) / (band_max - band_min + 1e-6)  # Normaliza√ß√£o\n",
        "\n",
        "            # Selecionando eixo correto na grade\n",
        "            ax = axes[i // 5, i % 5] if num_bands > 5 else axes[i]\n",
        "            ax.imshow(band, cmap='gray')\n",
        "            ax.set_title(f\"Banda {i+1}\")\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "        # Removendo eixos vazios, se houver\n",
        "        for j in range(i+1, len(axes.flatten())):\n",
        "            fig.delaxes(axes.flatten()[j])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def visualizar_patch_aleatorio(pasta_patches):\n",
        "    \"\"\"\n",
        "    Seleciona aleatoriamente um arquivo TIFF da pasta e exibe suas bandas.\n",
        "\n",
        "    Args:\n",
        "        pasta_patches (str): Caminho da pasta contendo os patches TIFF.\n",
        "    \"\"\"\n",
        "    # Obter a lista de arquivos na pasta\n",
        "    arquivos_tiff = [f for f in os.listdir(pasta_patches) if f.endswith(\".tiff\") or f.endswith(\".tif\")]\n",
        "\n",
        "    # Verificar se h√° arquivos na pasta\n",
        "    if not arquivos_tiff:\n",
        "        print(\"Nenhum arquivo TIFF encontrado na pasta.\")\n",
        "        return\n",
        "\n",
        "    # Escolher um arquivo aleatoriamente\n",
        "    tiff_escolhido = random.choice(arquivos_tiff)\n",
        "    tiff_path = os.path.join(pasta_patches, tiff_escolhido)\n",
        "\n",
        "    print(f\"üìÇ Exibindo: {tiff_escolhido}\")\n",
        "\n",
        "    # Abrir o arquivo e exibir as descri√ß√µes das bandas\n",
        "    with rasterio.open(tiff_path) as dataset:\n",
        "        num_bands = dataset.count\n",
        "        fig, axes = plt.subplots(nrows=(num_bands // 5) + 1, ncols=5, figsize=(15, (num_bands // 5) * 3))\n",
        "\n",
        "        for i in range(num_bands):\n",
        "            band = dataset.read(i + 1).astype(np.float32)  # Lendo a banda (come√ßa do 1)\n",
        "\n",
        "            # Obter valores m√≠nimo e m√°ximo da banda\n",
        "            band_min, band_max = np.nanmin(band), np.nanmax(band)\n",
        "            print(f\"üìä Banda {i+1} - M√≠n: {band_min}, M√°x: {band_max}\")\n",
        "\n",
        "            # Evitar normaliza√ß√£o errada se a banda for constante\n",
        "            if band_max == band_min:\n",
        "                # band = np.zeros_like(band)  # Evita dividir por zero, mantendo preto\n",
        "                band = np.ones_like(band)  # Evita dividir por zero, mantendo branco\n",
        "            else:\n",
        "                band = (band - band_min) / (band_max - band_min + 1e-6)  # Normaliza√ß√£o\n",
        "\n",
        "            # Selecionando eixo correto na grade\n",
        "            ax = axes[i // 5, i % 5] if num_bands > 5 else axes[i]\n",
        "            ax.imshow(band, cmap='gray', vmin=0, vmax=1)\n",
        "            ax.set_title(f\"Banda {i+1}\")\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "        # Removendo eixos vazios, se houver\n",
        "        for j in range(i+1, len(axes.flatten())):\n",
        "            fig.delaxes(axes.flatten()[j])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "IBP7VXiNCavb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from rasterio.enums import Resampling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "\n",
        "# üìå Configurar caminhos no Google Drive\n",
        "pasta_patches = \"/content/drive/MyDrive/Unb/Plantio_direto/Patches_32x32\"\n",
        "pasta_checkpoint = \"/content/drive/MyDrive/Unb/Autoencoder_Checkpoints\"\n",
        "pasta_logs = \"/content/drive/MyDrive/Unb/Autoencoder_Logs\"\n",
        "\n",
        "# Criar diret√≥rios, se n√£o existirem\n",
        "os.makedirs(pasta_checkpoint, exist_ok=True)\n",
        "os.makedirs(pasta_logs, exist_ok=True)\n",
        "\n",
        "# üîπ Definir os hiperpar√¢metros\n",
        "IMG_SIZE = 32\n",
        "NUM_BANDS = 16  # 16 bandas espectrais\n",
        "LATENT_DIM = 128  # Dimens√£o do espa√ßo latente\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "\n",
        "# üîπ Listar arquivos TIFF na pasta\n",
        "arquivos_tiff = [os.path.join(pasta_patches, f) for f in os.listdir(pasta_patches) if f.endswith(\".tif\")]\n",
        "\n",
        "# üîπ Fun√ß√£o para carregar imagens TIFF como arrays normalizados\n",
        "def carregar_patches(arquivos_tiff):\n",
        "    imagens = []\n",
        "    for arquivo in arquivos_tiff:\n",
        "        with rasterio.open(arquivo) as dataset:\n",
        "            img = dataset.read(out_shape=(NUM_BANDS, IMG_SIZE, IMG_SIZE), resampling=Resampling.bilinear)\n",
        "            img = img.astype(np.float32) / 255.0  # Normalizar para [0,1]\n",
        "            imagens.append(np.transpose(img, (1, 2, 0)))  # Converter para (32,32,16)\n",
        "    return np.array(imagens)\n",
        "\n",
        "# üîπ Carregar as imagens e dividir em treino/teste\n",
        "imagens = carregar_patches(arquivos_tiff)\n",
        "X_train, X_test = train_test_split(imagens, test_size=0.2, random_state=42)\n",
        "\n",
        "# üîπ Criar o Autoencoder\n",
        "def criar_autoencoder():\n",
        "    input_img = keras.Input(shape=(IMG_SIZE, IMG_SIZE, NUM_BANDS))\n",
        "\n",
        "    # Encoder\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    encoded = layers.Flatten()(x)\n",
        "    encoded = layers.Dense(LATENT_DIM, activation='relu')(encoded)\n",
        "\n",
        "    # Decoder\n",
        "    x = layers.Dense(8 * 8 * 128, activation='relu')(encoded)\n",
        "    x = layers.Reshape((8, 8, 128))(x)\n",
        "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    decoded = layers.Conv2D(NUM_BANDS, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    autoencoder = keras.Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "# üîπ Criar o modelo\n",
        "autoencoder = criar_autoencoder()\n",
        "\n",
        "# üîπ Configurar callbacks para salvar checkpoints e logs\n",
        "checkpoint_path = os.path.join(pasta_checkpoint, \"autoencoder_best.h5\")\n",
        "csv_logger_path = os.path.join(pasta_logs, \"training_log.csv\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "csv_logger = CSVLogger(csv_logger_path, append=True)\n",
        "\n",
        "# üîπ Treinar o Autoencoder\n",
        "history = autoencoder.fit(\n",
        "    X_train, X_train,\n",
        "    validation_data=(X_test, X_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[checkpoint, csv_logger]\n",
        ")\n",
        "\n",
        "# üîπ Salvar logs de treinamento em um DataFrame\n",
        "df_logs = pd.read_csv(csv_logger_path)\n",
        "print(df_logs.tail())  # Mostrar √∫ltimas entradas\n",
        "\n",
        "# üîπ Salvar modelo final\n",
        "modelo_final_path = os.path.join(pasta_checkpoint, \"autoencoder_final.h5\")\n",
        "autoencoder.save(modelo_final_path)\n",
        "\n",
        "print(f\"‚úÖ Treinamento conclu√≠do. Modelo salvo em: {modelo_final_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POF4TdEYjMe4",
        "outputId": "cb1fe828-ac6a-4324-b4d4-615ebf65ac6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.1322\n",
            "Epoch 1: val_loss improved from inf to 0.00435, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 285ms/step - loss: 0.1282 - val_loss: 0.0044\n",
            "Epoch 2/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.0043\n",
            "Epoch 2: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 3/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0043\n",
            "Epoch 3: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 4/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 0.0043\n",
            "Epoch 4: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 282ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 5/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0043\n",
            "Epoch 5: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 230ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 6/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.0043\n",
            "Epoch 6: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 247ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 7/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0043\n",
            "Epoch 7: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 202ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 8/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 0.0043\n",
            "Epoch 8: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 291ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 9/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0043\n",
            "Epoch 9: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 209ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 10/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 0.0043\n",
            "Epoch 10: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 11/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.0043\n",
            "Epoch 11: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 241ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 12/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 0.0043\n",
            "Epoch 12: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 300ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 13/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0043\n",
            "Epoch 13: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 232ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 14/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0043\n",
            "Epoch 14: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 217ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 15/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 0.0043\n",
            "Epoch 15: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 16/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0043\n",
            "Epoch 16: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 17/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 0.0043\n",
            "Epoch 17: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 322ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 18/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0043\n",
            "Epoch 18: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 211ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 19/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - loss: 0.0043\n",
            "Epoch 19: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 328ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 20/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0044\n",
            "Epoch 20: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 21/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 0.0044\n",
            "Epoch 21: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 401ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 22/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0043\n",
            "Epoch 22: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 23/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 0.0043\n",
            "Epoch 23: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 24/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0044\n",
            "Epoch 24: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 248ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 25/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0044\n",
            "Epoch 25: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 26/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - loss: 0.0043\n",
            "Epoch 26: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 288ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 27/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 0.0043\n",
            "Epoch 27: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 251ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 28/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0043\n",
            "Epoch 28: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 215ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 29/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 0.0043\n",
            "Epoch 29: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 286ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 30/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0044\n",
            "Epoch 30: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 31/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 0.0044\n",
            "Epoch 31: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 290ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 32/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0043\n",
            "Epoch 32: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 33/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 0.0043\n",
            "Epoch 33: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 34/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0043\n",
            "Epoch 34: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 208ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 35/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 0.0043\n",
            "Epoch 35: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 301ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 36/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.0043\n",
            "Epoch 36: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 240ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 37/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0043\n",
            "Epoch 37: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 207ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 38/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.0043\n",
            "Epoch 38: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 254ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 39/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0044\n",
            "Epoch 39: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 243ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 40/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0043\n",
            "Epoch 40: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 41/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 0.0044\n",
            "Epoch 41: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 297ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 42/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0043\n",
            "Epoch 42: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 43/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.0043\n",
            "Epoch 43: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 308ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 44/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0043\n",
            "Epoch 44: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 45/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 0.0043\n",
            "Epoch 45: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 274ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 46/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.0043\n",
            "Epoch 46: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 256ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 47/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0044\n",
            "Epoch 47: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 212ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 48/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0043\n",
            "Epoch 48: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 235ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 49/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - loss: 0.0043\n",
            "Epoch 49: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 253ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 50/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0043\n",
            "Epoch 50: val_loss did not improve from 0.00435\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 214ms/step - loss: 0.0043 - val_loss: 0.0044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    epoch      loss  val_loss\n",
            "45     45  0.004342  0.004351\n",
            "46     46  0.004342  0.004351\n",
            "47     47  0.004342  0.004351\n",
            "48     48  0.004342  0.004351\n",
            "49     49  0.004342  0.004351\n",
            "‚úÖ Treinamento conclu√≠do. Modelo salvo em: /content/drive/MyDrive/Unb/Autoencoder_Checkpoints/autoencoder_final.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ Caminho do log salvo\n",
        "csv_logger_path = \"/content/drive/MyDrive/Unb/Autoencoder_Logs/training_log.csv\"\n",
        "\n",
        "# üîπ Carregar log do treinamento\n",
        "df_logs = pd.read_csv(csv_logger_path)\n",
        "\n",
        "# üîπ Exibir √∫ltimas 10 √©pocas formatadas\n",
        "df_resumo = df_logs[['epoch', 'loss', 'val_loss']].tail(10)\n",
        "df_resumo.columns = ['√âpoca', 'Loss Treino', 'Loss Valida√ß√£o']\n",
        "\n",
        "# üîπ Ajustar casas decimais\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "\n",
        "# üîπ Exibir tabela formatada\n",
        "print(df_resumo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbPY5IEvHm9o",
        "outputId": "1bc3982e-cb7f-48c1-ea2f-3777fd2735e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    √âpoca  Loss Treino  Loss Valida√ß√£o\n",
            "40     40       0.0043          0.0044\n",
            "41     41       0.0043          0.0044\n",
            "42     42       0.0043          0.0044\n",
            "43     43       0.0043          0.0044\n",
            "44     44       0.0043          0.0044\n",
            "45     45       0.0043          0.0044\n",
            "46     46       0.0043          0.0044\n",
            "47     47       0.0043          0.0044\n",
            "48     48       0.0043          0.0044\n",
            "49     49       0.0043          0.0044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho da pasta com os patches\n",
        "pasta_patches = \"/content/drive/MyDrive/Unb/Plantio_direto/Patches_32x32\"\n",
        "\n",
        "# Lista de arquivos\n",
        "arquivos_tiff = [os.path.join(pasta_patches, f) for f in os.listdir(pasta_patches) if f.endswith(\".tif\") or f.endswith(\".tiff\")]\n",
        "\n",
        "# Seleciona um subconjunto pequeno para an√°lise (por exemplo, 10 arquivos)\n",
        "amostra_patches = np.random.choice(arquivos_tiff, min(10, len(arquivos_tiff)), replace=False)\n",
        "\n",
        "# Criar dataframe para armazenar estat√≠sticas\n",
        "estatisticas = []\n",
        "\n",
        "for tiff_path in amostra_patches:\n",
        "    with rasterio.open(tiff_path) as dataset:\n",
        "        num_bandas = dataset.count\n",
        "        for i in range(1, num_bandas + 1):\n",
        "            banda = dataset.read(i).astype(np.float32).flatten()\n",
        "            estatisticas.append({\n",
        "                \"Arquivo\": os.path.basename(tiff_path),\n",
        "                \"Banda\": i,\n",
        "                \"M√≠nimo\": np.min(banda),\n",
        "                \"M√°ximo\": np.max(banda),\n",
        "                \"M√©dia\": np.mean(banda),\n",
        "                \"Desvio Padr√£o\": np.std(banda)\n",
        "            })\n",
        "\n",
        "# Criar DataFrame com os resultados\n",
        "df_estatisticas = pd.DataFrame(estatisticas)\n",
        "print(df_estatisticas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM8jh_JxjPI-",
        "outputId": "004a69ef-0748-45fb-85a0-15edfda1c2cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Arquivo  Banda    M√≠nimo    M√°ximo     M√©dia  Desvio Padr√£o\n",
            "0    patch_221.tif      1  0.118566  0.129346  0.124402       0.002352\n",
            "1    patch_221.tif      2  0.101213  0.113435  0.107760       0.002404\n",
            "2    patch_221.tif      3  0.096277  0.110978  0.103410       0.002844\n",
            "3    patch_221.tif      4  0.121103  0.161957  0.133440       0.006797\n",
            "4    patch_221.tif      5  0.216456  0.259050  0.234366       0.007746\n",
            "..             ...    ...       ...       ...       ...            ...\n",
            "155  patch_485.tif     12  0.143933  0.329623  0.192626       0.039964\n",
            "156  patch_485.tif     13  0.087473  0.236057  0.126215       0.030779\n",
            "157  patch_485.tif     14 -0.400389 -0.263387 -0.312824       0.026671\n",
            "158  patch_485.tif     15 -0.410041 -0.287266 -0.354499       0.024116\n",
            "159  patch_485.tif     16  0.063471  0.163519  0.089393       0.020453\n",
            "\n",
            "[160 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tiff_path = \"/content/drive/MyDrive/Unb/Plantio_direto/Patches_32x32/patch_485.tif\"\n",
        "\n",
        "with rasterio.open(tiff_path) as dataset:\n",
        "    num_bandas = dataset.count  # N√∫mero total de bandas\n",
        "\n",
        "    for i in range(1, num_bandas + 1):\n",
        "        banda = dataset.read(i).astype(np.float32)  # Ler cada banda\n",
        "        min_val, max_val = np.nanpercentile(banda, [1, 99])\n",
        "        banda_normalizada = np.clip((banda - min_val) / (max_val - min_val + 1e-6), 0, 1)\n",
        "\n",
        "        print(f\"Banda {i}: Min={banda_normalizada.min():.4f}, Max={banda_normalizada.max():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMfEtWZDlo9D",
        "outputId": "5dc8419b-4bb1-4fa2-f881-dfca64424605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Banda 1: Min=0.0000, Max=1.0000\n",
            "Banda 2: Min=0.0000, Max=1.0000\n",
            "Banda 3: Min=0.0000, Max=1.0000\n",
            "Banda 4: Min=0.0000, Max=1.0000\n",
            "Banda 5: Min=0.0000, Max=1.0000\n",
            "Banda 6: Min=0.0000, Max=1.0000\n",
            "Banda 7: Min=0.0000, Max=1.0000\n",
            "Banda 8: Min=0.0000, Max=1.0000\n",
            "Banda 9: Min=0.0000, Max=1.0000\n",
            "Banda 10: Min=0.0000, Max=1.0000\n",
            "Banda 11: Min=0.0000, Max=1.0000\n",
            "Banda 12: Min=0.0000, Max=1.0000\n",
            "Banda 13: Min=0.0000, Max=1.0000\n",
            "Banda 14: Min=0.0000, Max=1.0000\n",
            "Banda 15: Min=0.0000, Max=1.0000\n",
            "Banda 16: Min=0.0000, Max=1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from rasterio.enums import Resampling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "\n",
        "# üìå Configurar caminhos no Google Drive\n",
        "pasta_patches = \"/content/drive/MyDrive/Unb/Plantio_direto/Patches_32x32\"\n",
        "pasta_checkpoint = \"/content/drive/MyDrive/Unb/Autoencoder_Checkpoints_2\"\n",
        "pasta_logs = \"/content/drive/MyDrive/Unb/Autoencoder_Logs_2\"\n",
        "\n",
        "# Criar diret√≥rios, se n√£o existirem\n",
        "os.makedirs(pasta_checkpoint, exist_ok=True)\n",
        "os.makedirs(pasta_logs, exist_ok=True)\n",
        "\n",
        "# üîπ Definir os hiperpar√¢metros\n",
        "IMG_SIZE = 32\n",
        "NUM_BANDS = 16  # 16 bandas espectrais\n",
        "LATENT_DIM = 128  # Dimens√£o do espa√ßo latente\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "\n",
        "# üîπ Listar arquivos TIFF na pasta\n",
        "arquivos_tiff = [os.path.join(pasta_patches, f) for f in os.listdir(pasta_patches) if f.endswith(\".tif\")]\n",
        "\n",
        "# üîπ Fun√ß√£o para carregar imagens TIFF como arrays normalizados\n",
        "def carregar_patches(arquivos_tiff):\n",
        "    imagens = []\n",
        "    for arquivo in arquivos_tiff:\n",
        "        with rasterio.open(arquivo) as dataset:\n",
        "            img = dataset.read(out_shape=(NUM_BANDS, IMG_SIZE, IMG_SIZE), resampling=Resampling.bilinear)\n",
        "            img = img.astype(np.float32)\n",
        "            img = np.transpose(img, (1, 2, 0))  # Converter para (32,32,16)\n",
        "            imagens.append(img)\n",
        "    return np.array(imagens)\n",
        "\n",
        "# üîπ Carregar as imagens e dividir em treino/teste\n",
        "imagens = carregar_patches(arquivos_tiff)\n",
        "X_train, X_test = train_test_split(imagens, test_size=0.2, random_state=42)\n",
        "\n",
        "# üîπ Criar o Autoencoder com Normaliza√ß√£o e Camada Adicional\n",
        "def criar_autoencoder():\n",
        "    input_img = keras.Input(shape=(IMG_SIZE, IMG_SIZE, NUM_BANDS))\n",
        "\n",
        "    # üîπ Normaliza√ß√£o\n",
        "    x = layers.LayerNormalization()(input_img)  # Normaliza as bandas espectrais antes da convolu√ß√£o\n",
        "\n",
        "    # üîπ Encoder (Ajustado)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)  # ‚¨ÖÔ∏è **Nova camada**\n",
        "    encoded = layers.Flatten()(x)\n",
        "    encoded = layers.Dense(LATENT_DIM, activation='relu')(encoded)\n",
        "\n",
        "    # üîπ Decoder (Ajustado)\n",
        "    x = layers.Dense(8 * 8 * 256, activation='relu')(encoded)  # Correspondendo ao novo encoder\n",
        "    x = layers.Reshape((8, 8, 256))(x)\n",
        "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    decoded = layers.Conv2D(NUM_BANDS, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    autoencoder = keras.Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "# üîπ Criar o modelo\n",
        "autoencoder = criar_autoencoder()\n",
        "\n",
        "# üîπ Configurar callbacks para salvar checkpoints e logs\n",
        "checkpoint_path = os.path.join(pasta_checkpoint, \"autoencoder_best.h5\")\n",
        "csv_logger_path = os.path.join(pasta_logs, \"training_log.csv\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "csv_logger = CSVLogger(csv_logger_path, append=True)\n",
        "\n",
        "# üîπ Treinar o Autoencoder\n",
        "history = autoencoder.fit(\n",
        "    X_train, X_train,\n",
        "    validation_data=(X_test, X_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[checkpoint, csv_logger]\n",
        ")\n",
        "\n",
        "# üîπ Salvar logs de treinamento em um DataFrame\n",
        "df_logs = pd.read_csv(csv_logger_path)\n",
        "print(df_logs.tail())  # Mostrar √∫ltimas entradas\n",
        "\n",
        "# üîπ Salvar modelo final\n",
        "modelo_final_path = os.path.join(pasta_checkpoint, \"autoencoder_final.h5\")\n",
        "autoencoder.save(modelo_final_path)\n",
        "\n",
        "print(f\"‚úÖ Treinamento conclu√≠do. Modelo salvo em: {modelo_final_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Hc0fhjtfF8X1",
        "outputId": "0f8c423c-79c8-4e97-f395-dc6f1bc4e90f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - loss: 11377.3535\n",
            "Epoch 1: val_loss improved from inf to 11365.26172, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_2/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 696ms/step - loss: 11376.7949 - val_loss: 11365.2617\n",
            "Epoch 2/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - loss: 11360.5898\n",
            "Epoch 2: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 708ms/step - loss: 11360.6455 - val_loss: 11365.2617\n",
            "Epoch 3/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - loss: 11368.7100\n",
            "Epoch 3: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 515ms/step - loss: 11368.3389 - val_loss: 11365.2617\n",
            "Epoch 4/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610ms/step - loss: 11367.0576\n",
            "Epoch 4: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 689ms/step - loss: 11366.7725 - val_loss: 11365.2617\n",
            "Epoch 5/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step - loss: 11362.5498\n",
            "Epoch 5: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 697ms/step - loss: 11362.5029 - val_loss: 11365.2617\n",
            "Epoch 6/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - loss: 11357.3496\n",
            "Epoch 6: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 502ms/step - loss: 11357.5762 - val_loss: 11365.2617\n",
            "Epoch 7/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512ms/step - loss: 11360.3252\n",
            "Epoch 7: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 589ms/step - loss: 11360.3955 - val_loss: 11365.2617\n",
            "Epoch 8/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - loss: 11359.3232\n",
            "Epoch 8: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 631ms/step - loss: 11359.4453 - val_loss: 11365.2617\n",
            "Epoch 9/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - loss: 11364.8730\n",
            "Epoch 9: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 493ms/step - loss: 11364.7041 - val_loss: 11365.2617\n",
            "Epoch 10/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - loss: 11364.1162\n",
            "Epoch 10: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 561ms/step - loss: 11363.9863 - val_loss: 11365.2617\n",
            "Epoch 11/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step - loss: 11365.9268\n",
            "Epoch 11: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 650ms/step - loss: 11365.7012 - val_loss: 11365.2617\n",
            "Epoch 12/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - loss: 11364.5029\n",
            "Epoch 12: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 544ms/step - loss: 11364.3525 - val_loss: 11365.2617\n",
            "Epoch 13/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - loss: 11365.9590\n",
            "Epoch 13: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 675ms/step - loss: 11365.7324 - val_loss: 11365.2617\n",
            "Epoch 14/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - loss: 11363.3906\n",
            "Epoch 14: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 533ms/step - loss: 11363.2988 - val_loss: 11365.2617\n",
            "Epoch 15/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - loss: 11370.1094\n",
            "Epoch 15: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 573ms/step - loss: 11369.6641 - val_loss: 11365.2617\n",
            "Epoch 16/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - loss: 11358.5840\n",
            "Epoch 16: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 982ms/step - loss: 11358.7451 - val_loss: 11365.2617\n",
            "Epoch 17/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596ms/step - loss: 11355.8691\n",
            "Epoch 17: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 636ms/step - loss: 11356.1738 - val_loss: 11365.2617\n",
            "Epoch 18/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - loss: 11360.7842\n",
            "Epoch 18: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 558ms/step - loss: 11360.8301 - val_loss: 11365.2617\n",
            "Epoch 19/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - loss: 11352.7676\n",
            "Epoch 19: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 540ms/step - loss: 11353.2354 - val_loss: 11365.2617\n",
            "Epoch 20/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665ms/step - loss: 11363.3340\n",
            "Epoch 20: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 742ms/step - loss: 11363.2451 - val_loss: 11365.2617\n",
            "Epoch 21/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517ms/step - loss: 11362.8203\n",
            "Epoch 21: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 557ms/step - loss: 11362.7588 - val_loss: 11365.2617\n",
            "Epoch 22/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641ms/step - loss: 11363.9531\n",
            "Epoch 22: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 682ms/step - loss: 11363.8320 - val_loss: 11365.2617\n",
            "Epoch 23/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - loss: 11358.0273\n",
            "Epoch 23: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 582ms/step - loss: 11358.2188 - val_loss: 11365.2617\n",
            "Epoch 24/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791ms/step - loss: 11361.8447\n",
            "Epoch 24: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 871ms/step - loss: 11361.8350 - val_loss: 11365.2617\n",
            "Epoch 25/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703ms/step - loss: 11363.8643\n",
            "Epoch 25: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 873ms/step - loss: 11363.7480 - val_loss: 11365.2617\n",
            "Epoch 26/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - loss: 11359.6914\n",
            "Epoch 26: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 672ms/step - loss: 11359.7949 - val_loss: 11365.2617\n",
            "Epoch 27/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575ms/step - loss: 11365.9805\n",
            "Epoch 27: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 614ms/step - loss: 11365.7529 - val_loss: 11365.2617\n",
            "Epoch 28/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - loss: 11358.4209\n",
            "Epoch 28: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 605ms/step - loss: 11358.5908 - val_loss: 11365.2617\n",
            "Epoch 29/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606ms/step - loss: 11356.1826\n",
            "Epoch 29: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 684ms/step - loss: 11356.4707 - val_loss: 11365.2617\n",
            "Epoch 30/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - loss: 11360.9805\n",
            "Epoch 30: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 549ms/step - loss: 11361.0156 - val_loss: 11365.2617\n",
            "Epoch 31/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - loss: 11356.6055\n",
            "Epoch 31: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 663ms/step - loss: 11356.8711 - val_loss: 11365.2617\n",
            "Epoch 32/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - loss: 11362.5732\n",
            "Epoch 32: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 593ms/step - loss: 11362.5244 - val_loss: 11365.2617\n",
            "Epoch 33/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625ms/step - loss: 11363.1982\n",
            "Epoch 33: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 667ms/step - loss: 11363.1172 - val_loss: 11365.2617\n",
            "Epoch 34/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - loss: 11361.5879\n",
            "Epoch 34: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 555ms/step - loss: 11361.5908 - val_loss: 11365.2617\n",
            "Epoch 35/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - loss: 11363.7129\n",
            "Epoch 35: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 582ms/step - loss: 11363.6045 - val_loss: 11365.2617\n",
            "Epoch 36/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610ms/step - loss: 11358.5146\n",
            "Epoch 36: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 689ms/step - loss: 11358.6797 - val_loss: 11365.2617\n",
            "Epoch 37/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - loss: 11364.2520\n",
            "Epoch 37: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 534ms/step - loss: 11364.1152 - val_loss: 11365.2617\n",
            "Epoch 38/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - loss: 11364.5078\n",
            "Epoch 38: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 538ms/step - loss: 11364.3574 - val_loss: 11365.2617\n",
            "Epoch 39/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586ms/step - loss: 11359.4863\n",
            "Epoch 39: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 628ms/step - loss: 11359.5996 - val_loss: 11365.2617\n",
            "Epoch 40/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541ms/step - loss: 11366.4355\n",
            "Epoch 40: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 620ms/step - loss: 11366.1846 - val_loss: 11365.2617\n",
            "Epoch 41/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - loss: 11362.1387\n",
            "Epoch 41: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 563ms/step - loss: 11362.1133 - val_loss: 11365.2617\n",
            "Epoch 42/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - loss: 11367.3105\n",
            "Epoch 42: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 673ms/step - loss: 11367.0127 - val_loss: 11365.2617\n",
            "Epoch 43/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - loss: 11362.6338\n",
            "Epoch 43: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 595ms/step - loss: 11362.5820 - val_loss: 11365.2617\n",
            "Epoch 44/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - loss: 11364.0127\n",
            "Epoch 44: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 547ms/step - loss: 11363.8877 - val_loss: 11365.2617\n",
            "Epoch 45/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - loss: 11366.7148\n",
            "Epoch 45: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 665ms/step - loss: 11366.4482 - val_loss: 11365.2617\n",
            "Epoch 46/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - loss: 11359.9170\n",
            "Epoch 46: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 565ms/step - loss: 11360.0088 - val_loss: 11365.2617\n",
            "Epoch 47/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580ms/step - loss: 11361.7363\n",
            "Epoch 47: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 657ms/step - loss: 11361.7324 - val_loss: 11365.2617\n",
            "Epoch 48/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622ms/step - loss: 11361.6562\n",
            "Epoch 48: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 699ms/step - loss: 11361.6562 - val_loss: 11365.2617\n",
            "Epoch 49/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - loss: 11365.9453\n",
            "Epoch 49: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 615ms/step - loss: 11365.7188 - val_loss: 11365.2617\n",
            "Epoch 50/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606ms/step - loss: 11360.2695\n",
            "Epoch 50: val_loss did not improve from 11365.26172\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 686ms/step - loss: 11360.3418 - val_loss: 11365.2617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    epoch          loss      val_loss\n",
            "45     45  11361.653320  11365.261719\n",
            "46     46  11361.653320  11365.261719\n",
            "47     47  11361.653320  11365.261719\n",
            "48     48  11361.652344  11365.261719\n",
            "49     49  11361.653320  11365.261719\n",
            "‚úÖ Treinamento conclu√≠do. Modelo salvo em: /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_2/autoencoder_final.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ Caminho do log salvo\n",
        "csv_logger_path = \"/content/drive/MyDrive/Unb/Autoencoder_Logs_2/training_log.csv\"\n",
        "\n",
        "# üîπ Carregar log do treinamento\n",
        "df_logs = pd.read_csv(csv_logger_path)\n",
        "\n",
        "# üîπ Exibir √∫ltimas 10 √©pocas formatadas\n",
        "df_resumo = df_logs[['epoch', 'loss', 'val_loss']].tail(10)\n",
        "df_resumo.columns = ['√âpoca', 'Loss Treino', 'Loss Valida√ß√£o']\n",
        "\n",
        "# üîπ Ajustar casas decimais\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "\n",
        "# üîπ Exibir tabela formatada\n",
        "print(df_resumo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhctlNPWHsmR",
        "outputId": "8f402f8c-4fcb-4768-b01a-fd23663b5b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    √âpoca  Loss Treino  Loss Valida√ß√£o\n",
            "40     40   11361.6533      11365.2617\n",
            "41     41   11361.6523      11365.2617\n",
            "42     42   11361.6533      11365.2617\n",
            "43     43   11361.6523      11365.2617\n",
            "44     44   11361.6543      11365.2617\n",
            "45     45   11361.6533      11365.2617\n",
            "46     46   11361.6533      11365.2617\n",
            "47     47   11361.6533      11365.2617\n",
            "48     48   11361.6523      11365.2617\n",
            "49     49   11361.6533      11365.2617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from rasterio.enums import Resampling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau\n",
        "\n",
        "# üìå Caminhos no Google Drive\n",
        "pasta_patches = \"/content/drive/MyDrive/Unb/Plantio_direto/Patches_32x32\"\n",
        "pasta_checkpoint = \"/content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3\"\n",
        "pasta_logs = \"/content/drive/MyDrive/Unb/Autoencoder_Logs_3\"\n",
        "\n",
        "# Criar diret√≥rios, se n√£o existirem\n",
        "os.makedirs(pasta_checkpoint, exist_ok=True)\n",
        "os.makedirs(pasta_logs, exist_ok=True)\n",
        "\n",
        "# üîπ Hiperpar√¢metros\n",
        "IMG_SIZE = 32\n",
        "NUM_BANDS = 16\n",
        "LATENT_DIM = 128\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "\n",
        "# üîπ Normalizador global para os patches\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# üîπ Fun√ß√£o para carregar e normalizar imagens TIFF\n",
        "def carregar_patches(arquivos_tiff):\n",
        "    imagens = []\n",
        "    for arquivo in arquivos_tiff:\n",
        "        with rasterio.open(arquivo) as dataset:\n",
        "            img = dataset.read(out_shape=(NUM_BANDS, IMG_SIZE, IMG_SIZE), resampling=Resampling.bilinear)\n",
        "            img = img.astype(np.float32)\n",
        "            img = np.transpose(img, (1, 2, 0))  # (32,32,16)\n",
        "\n",
        "            # üîπ Normalizar valores (MinMaxScaler)\n",
        "            img = img.reshape(-1, NUM_BANDS)\n",
        "            img = scaler.fit_transform(img)  # Normalizar entre 0 e 1\n",
        "            img = img.reshape(IMG_SIZE, IMG_SIZE, NUM_BANDS)\n",
        "\n",
        "            imagens.append(img)\n",
        "\n",
        "    return np.array(imagens)\n",
        "\n",
        "# üîπ Carregar imagens e dividir em treino/teste\n",
        "arquivos_tiff = [os.path.join(pasta_patches, f) for f in os.listdir(pasta_patches) if f.endswith(\".tif\")]\n",
        "imagens = carregar_patches(arquivos_tiff)\n",
        "X_train, X_test = train_test_split(imagens, test_size=0.2, random_state=42)\n",
        "\n",
        "# üîπ Criar o Autoencoder ajustado\n",
        "def criar_autoencoder():\n",
        "    input_img = keras.Input(shape=(IMG_SIZE, IMG_SIZE, NUM_BANDS))\n",
        "\n",
        "    # üîπ Encoder (com BatchNormalization e Dropout)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.2)(x)  # üîπ Dropout para regulariza√ß√£o\n",
        "\n",
        "    encoded = layers.Flatten()(x)\n",
        "    encoded = layers.Dense(LATENT_DIM, activation='relu')(encoded)\n",
        "\n",
        "    # üîπ Decoder\n",
        "    x = layers.Dense(8 * 8 * 128, activation='relu')(encoded)\n",
        "    x = layers.Reshape((8, 8, 128))(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "    decoded = layers.Conv2D(NUM_BANDS, (3, 3), activation='linear', padding='same')(x)  # üîπ Sa√≠da com ativa√ß√£o 'linear'\n",
        "\n",
        "    autoencoder = keras.Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005), loss='mse')  # üîπ Reduzi taxa de aprendizado\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "# üîπ Criar modelo\n",
        "autoencoder = criar_autoencoder()\n",
        "\n",
        "# üîπ Callbacks (Salvar checkpoints, reduzir LR dinamicamente)\n",
        "checkpoint_path = os.path.join(pasta_checkpoint, \"autoencoder_best.h5\")\n",
        "csv_logger_path = os.path.join(pasta_logs, \"training_log.csv\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "csv_logger = CSVLogger(csv_logger_path, append=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# üîπ Treinar o modelo\n",
        "history = autoencoder.fit(\n",
        "    X_train, X_train,\n",
        "    validation_data=(X_test, X_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[checkpoint, csv_logger, reduce_lr]\n",
        ")\n",
        "\n",
        "# üîπ Salvar logs do treinamento\n",
        "df_logs = pd.read_csv(csv_logger_path)\n",
        "print(df_logs.tail())\n",
        "\n",
        "# üîπ Salvar modelo final\n",
        "modelo_final_path = os.path.join(pasta_checkpoint, \"autoencoder_final.h5\")\n",
        "autoencoder.save(modelo_final_path)\n",
        "\n",
        "print(f\"‚úÖ Treinamento conclu√≠do. Modelo salvo em: {modelo_final_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZEKLRq2HGkC",
        "outputId": "1d743f1e-e5c2-4bd8-8090-dd8f7ebb8353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 0.1789\n",
            "Epoch 1: val_loss improved from inf to 0.23799, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 331ms/step - loss: 0.1757 - val_loss: 0.2380 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - loss: 0.0633\n",
            "Epoch 2: val_loss improved from 0.23799 to 0.20697, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 381ms/step - loss: 0.0632 - val_loss: 0.2070 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.0484\n",
            "Epoch 3: val_loss improved from 0.20697 to 0.17141, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 270ms/step - loss: 0.0483 - val_loss: 0.1714 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 0.0401\n",
            "Epoch 4: val_loss improved from 0.17141 to 0.14583, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 324ms/step - loss: 0.0401 - val_loss: 0.1458 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 0.0351\n",
            "Epoch 5: val_loss improved from 0.14583 to 0.12922, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 297ms/step - loss: 0.0351 - val_loss: 0.1292 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0319\n",
            "Epoch 6: val_loss improved from 0.12922 to 0.11747, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 247ms/step - loss: 0.0319 - val_loss: 0.1175 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 0.0312\n",
            "Epoch 7: val_loss improved from 0.11747 to 0.10185, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 268ms/step - loss: 0.0312 - val_loss: 0.1019 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - loss: 0.0284\n",
            "Epoch 8: val_loss improved from 0.10185 to 0.09249, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 375ms/step - loss: 0.0284 - val_loss: 0.0925 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0272\n",
            "Epoch 9: val_loss improved from 0.09249 to 0.07913, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 248ms/step - loss: 0.0272 - val_loss: 0.0791 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 0.0274\n",
            "Epoch 10: val_loss improved from 0.07913 to 0.07864, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 328ms/step - loss: 0.0274 - val_loss: 0.0786 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.0260\n",
            "Epoch 11: val_loss improved from 0.07864 to 0.06875, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 283ms/step - loss: 0.0260 - val_loss: 0.0687 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - loss: 0.0249\n",
            "Epoch 12: val_loss improved from 0.06875 to 0.06350, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 359ms/step - loss: 0.0248 - val_loss: 0.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.0241\n",
            "Epoch 13: val_loss improved from 0.06350 to 0.05650, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 273ms/step - loss: 0.0241 - val_loss: 0.0565 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - loss: 0.0239\n",
            "Epoch 14: val_loss did not improve from 0.05650\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 375ms/step - loss: 0.0239 - val_loss: 0.0596 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - loss: 0.0221\n",
            "Epoch 15: val_loss improved from 0.05650 to 0.05518, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - loss: 0.0221 - val_loss: 0.0552 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 0.0216\n",
            "Epoch 16: val_loss did not improve from 0.05518\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 332ms/step - loss: 0.0216 - val_loss: 0.0553 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - loss: 0.0213\n",
            "Epoch 17: val_loss improved from 0.05518 to 0.04999, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 352ms/step - loss: 0.0213 - val_loss: 0.0500 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 0.0205\n",
            "Epoch 18: val_loss improved from 0.04999 to 0.04417, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 303ms/step - loss: 0.0205 - val_loss: 0.0442 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - loss: 0.0202\n",
            "Epoch 19: val_loss improved from 0.04417 to 0.03920, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 412ms/step - loss: 0.0202 - val_loss: 0.0392 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 0.0201\n",
            "Epoch 20: val_loss did not improve from 0.03920\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 261ms/step - loss: 0.0201 - val_loss: 0.0435 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - loss: 0.0196\n",
            "Epoch 21: val_loss improved from 0.03920 to 0.03562, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 386ms/step - loss: 0.0195 - val_loss: 0.0356 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 0.0183\n",
            "Epoch 22: val_loss improved from 0.03562 to 0.03400, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 264ms/step - loss: 0.0183 - val_loss: 0.0340 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - loss: 0.0177\n",
            "Epoch 23: val_loss improved from 0.03400 to 0.02911, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 377ms/step - loss: 0.0177 - val_loss: 0.0291 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0180\n",
            "Epoch 24: val_loss did not improve from 0.02911\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 247ms/step - loss: 0.0180 - val_loss: 0.0356 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - loss: 0.0177\n",
            "Epoch 25: val_loss did not improve from 0.02911\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 281ms/step - loss: 0.0178 - val_loss: 0.0304 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 0.0178\n",
            "Epoch 26: val_loss did not improve from 0.02911\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 310ms/step - loss: 0.0178 - val_loss: 0.0324 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0184\n",
            "Epoch 27: val_loss did not improve from 0.02911\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 228ms/step - loss: 0.0184 - val_loss: 0.0296 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 0.0171\n",
            "Epoch 28: val_loss did not improve from 0.02911\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 299ms/step - loss: 0.0171 - val_loss: 0.0385 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 0.0190\n",
            "Epoch 29: val_loss improved from 0.02911 to 0.02689, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 286ms/step - loss: 0.0189 - val_loss: 0.0269 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - loss: 0.0159\n",
            "Epoch 30: val_loss improved from 0.02689 to 0.02509, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 365ms/step - loss: 0.0159 - val_loss: 0.0251 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.0153\n",
            "Epoch 31: val_loss did not improve from 0.02509\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - loss: 0.0153 - val_loss: 0.0264 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0149\n",
            "Epoch 32: val_loss improved from 0.02509 to 0.02509, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 428ms/step - loss: 0.0149 - val_loss: 0.0251 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0146\n",
            "Epoch 33: val_loss did not improve from 0.02509\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 247ms/step - loss: 0.0146 - val_loss: 0.0252 - learning_rate: 2.5000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - loss: 0.0143\n",
            "Epoch 34: val_loss improved from 0.02509 to 0.02456, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 376ms/step - loss: 0.0143 - val_loss: 0.0246 - learning_rate: 2.5000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.0141\n",
            "Epoch 35: val_loss improved from 0.02456 to 0.02325, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 252ms/step - loss: 0.0141 - val_loss: 0.0232 - learning_rate: 2.5000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - loss: 0.0141\n",
            "Epoch 36: val_loss improved from 0.02325 to 0.02306, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 377ms/step - loss: 0.0141 - val_loss: 0.0231 - learning_rate: 2.5000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 0.0142\n",
            "Epoch 37: val_loss improved from 0.02306 to 0.02272, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 289ms/step - loss: 0.0142 - val_loss: 0.0227 - learning_rate: 2.5000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - loss: 0.0135\n",
            "Epoch 38: val_loss improved from 0.02272 to 0.02246, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 382ms/step - loss: 0.0135 - val_loss: 0.0225 - learning_rate: 2.5000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0136\n",
            "Epoch 39: val_loss did not improve from 0.02246\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 235ms/step - loss: 0.0136 - val_loss: 0.0236 - learning_rate: 2.5000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 0.0135\n",
            "Epoch 40: val_loss improved from 0.02246 to 0.02164, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - loss: 0.0135 - val_loss: 0.0216 - learning_rate: 2.5000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - loss: 0.0135\n",
            "Epoch 41: val_loss did not improve from 0.02164\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 256ms/step - loss: 0.0135 - val_loss: 0.0220 - learning_rate: 2.5000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 0.0131\n",
            "Epoch 42: val_loss did not improve from 0.02164\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 331ms/step - loss: 0.0131 - val_loss: 0.0226 - learning_rate: 2.5000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.0131\n",
            "Epoch 43: val_loss did not improve from 0.02164\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 251ms/step - loss: 0.0131 - val_loss: 0.0225 - learning_rate: 2.5000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - loss: 0.0134\n",
            "Epoch 44: val_loss did not improve from 0.02164\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 349ms/step - loss: 0.0134 - val_loss: 0.0240 - learning_rate: 2.5000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.0134\n",
            "Epoch 45: val_loss improved from 0.02164 to 0.02142, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 280ms/step - loss: 0.0134 - val_loss: 0.0214 - learning_rate: 2.5000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - loss: 0.0130\n",
            "Epoch 46: val_loss did not improve from 0.02142\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 353ms/step - loss: 0.0130 - val_loss: 0.0217 - learning_rate: 2.5000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0125\n",
            "Epoch 47: val_loss improved from 0.02142 to 0.02106, saving model to /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 264ms/step - loss: 0.0125 - val_loss: 0.0211 - learning_rate: 2.5000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - loss: 0.0126\n",
            "Epoch 48: val_loss did not improve from 0.02106\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 349ms/step - loss: 0.0126 - val_loss: 0.0215 - learning_rate: 2.5000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 0.0128\n",
            "Epoch 49: val_loss did not improve from 0.02106\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 249ms/step - loss: 0.0128 - val_loss: 0.0214 - learning_rate: 2.5000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - loss: 0.0124\n",
            "Epoch 50: val_loss did not improve from 0.02106\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 358ms/step - loss: 0.0124 - val_loss: 0.0218 - learning_rate: 2.5000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    epoch      loss  val_loss\n",
            "45     45  0.012904  0.021734\n",
            "46     46  0.012613  0.021057\n",
            "47     47  0.012525  0.021512\n",
            "48     48  0.012638  0.021403\n",
            "49     49  0.012382  0.021758\n",
            "‚úÖ Treinamento conclu√≠do. Modelo salvo em: /content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_final.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ Caminho do log salvo\n",
        "csv_logger_path = \"/content/drive/MyDrive/Unb/Autoencoder_Logs_3/training_log.csv\"\n",
        "\n",
        "# üîπ Carregar log do treinamento\n",
        "df_logs = pd.read_csv(csv_logger_path)\n",
        "\n",
        "# üîπ Exibir √∫ltimas 10 √©pocas formatadas\n",
        "df_resumo = df_logs[['epoch', 'loss', 'val_loss']].tail(10)\n",
        "df_resumo.columns = ['√âpoca', 'Loss Treino', 'Loss Valida√ß√£o']\n",
        "\n",
        "# üîπ Ajustar casas decimais\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "\n",
        "# üîπ Exibir tabela formatada\n",
        "print(df_resumo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bKVk0ScHvsG",
        "outputId": "3c373a27-c204-49a5-8aad-63c6f3488fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    √âpoca  Loss Treino  Loss Valida√ß√£o\n",
            "40     40       0.0133          0.0220\n",
            "41     41       0.0131          0.0226\n",
            "42     42       0.0132          0.0225\n",
            "43     43       0.0136          0.0240\n",
            "44     44       0.0132          0.0214\n",
            "45     45       0.0129          0.0217\n",
            "46     46       0.0126          0.0211\n",
            "47     47       0.0125          0.0215\n",
            "48     48       0.0126          0.0214\n",
            "49     49       0.0124          0.0218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow.keras.losses\n",
        "\n",
        "# üîπ Caminho do modelo treinado e de um patch de exemplo\n",
        "model_path = \"/content/drive/MyDrive/Unb/Autoencoder_Checkpoints_3/autoencoder_final.h5\"\n",
        "sample_image_path = \"/content/drive/MyDrive/Unb/Plantio_direto/Patches_32x32/patch_302.tif\"\n",
        "\n",
        "\n",
        "# Registrar manualmente a m√©trica MSE\n",
        "custom_objects = {\"mse\": tensorflow.keras.losses.MeanSquaredError()}\n",
        "\n",
        "# Agora carregue o modelo com a m√©trica registrada\n",
        "autoencoder = load_model(model_path, custom_objects=custom_objects)\n",
        "\n",
        "\n",
        "# üîπ Fun√ß√£o para normalizar imagem\n",
        "def normalize(img):\n",
        "    min_val, max_val = np.nanpercentile(img, [1, 99])\n",
        "    return np.clip((img - min_val) / (max_val - min_val + 1e-6), 0, 1)\n",
        "\n",
        "# üîπ Carregar patch e processar\n",
        "with rasterio.open(sample_image_path) as dataset:\n",
        "    img = dataset.read().astype(np.float32)  # (C, H, W)\n",
        "    img_rgb = np.stack([normalize(img[3]), normalize(img[2]), normalize(img[1])], axis=-1)  # Bandas 4,3,2 (RGB)\n",
        "    img_input = np.expand_dims(img, axis=0)  # Adiciona batch dimension\n",
        "    img_input = np.transpose(img_input, (0, 2, 3, 1))\n",
        "\n",
        "\n",
        "\n",
        "# üîπ Predi√ß√£o pelo autoencoder\n",
        "reconstructed = autoencoder.predict(img_input)\n",
        "reconstructed_rgb = np.stack([normalize(reconstructed[0, 3]), normalize(reconstructed[0, 2]), normalize(reconstructed[0, 1])], axis=-1)\n",
        "\n",
        "# üîπ Definir classe atribu√≠da (Exemplo: clustering)\n",
        "predicted_class = np.random.choice([\"Grupo 1\", \"Grupo 2\", \"Grupo 3\"])  # Substituir por classifica√ß√£o real\n",
        "\n",
        "# üîπ Visualizar resultados\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axes[0].imshow(img_rgb)\n",
        "axes[0].set_title(\"Imagem Original\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(reconstructed_rgb)\n",
        "axes[1].set_title(\"Reconstru√ß√£o pelo Autoencoder\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "axes[2].text(0.5, 0.5, predicted_class, fontsize=20, ha='center', va='center', bbox=dict(facecolor='lightgray', edgecolor='black'))\n",
        "axes[2].set_title(\"Classe Atribu√≠da\")\n",
        "axes[2].axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "zyW3zs_LLmU7",
        "outputId": "c8b15b4d-20c5-4036-8e0b-fde042ec45a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}